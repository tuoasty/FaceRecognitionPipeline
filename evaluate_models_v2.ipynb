{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "5d78e53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pickle\n",
    "import json\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_curve, auc, average_precision_score\n",
    "from scipy import stats\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "9ddce237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project Root: d:\\KEVIN\\0SLC\\RIG\n",
      "Output Root: d:\\KEVIN\\0SLC\\RIG\\output\\v0\n"
     ]
    }
   ],
   "source": [
    "NOTEBOOK_DIR = Path.cwd()\n",
    "\n",
    "def find_project_root(start: Path, target_folder=\"RIG\"):\n",
    "  for parent in [start] + list(start.parents):\n",
    "    if parent.name == target_folder:\n",
    "      return parent\n",
    "  raise RuntimeError(f\"Could not find project root '{target_folder}'\")\n",
    "\n",
    "PROJECT_ROOT = find_project_root(NOTEBOOK_DIR)\n",
    "OUTPUT_ROOT = PROJECT_ROOT / \"output\" / \"v0\"\n",
    "\n",
    "print(f\"Project Root: {PROJECT_ROOT}\")\n",
    "print(f\"Output Root: {OUTPUT_ROOT}\")\n",
    "\n",
    "output_root = Path(OUTPUT_ROOT)\n",
    "embeddings_root = output_root / 'embeddings'\n",
    "results_dir = output_root / 'evaluation_results'\n",
    "plots_dir = results_dir / 'plots'\n",
    "plots_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "models = [\n",
    "  'adaface_ir_50',\n",
    "  'adaface_ir_101',\n",
    "  'arcface_ir_50',\n",
    "  'arcface_ir_101'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "e3f0249f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embeddings(model_name: str) -> Dict:\n",
    "  model_dir = embeddings_root / model_name\n",
    "  \n",
    "  if not model_dir.exists():\n",
    "    raise FileNotFoundError(f\"Model directory not found: {model_dir}\")\n",
    "  \n",
    "  embeddings = {}\n",
    "\n",
    "  embedding_files = {\n",
    "    'gallery_oneshot_base': 'gallery_one-shot_base.pkl',\n",
    "    'gallery_oneshot_augmented': 'gallery_one-shot_augmented.pkl',\n",
    "    'gallery_fewshot_base': 'gallery_few-shot_base.pkl',\n",
    "    'gallery_fewshot_augmented': 'gallery_few-shot_augmented.pkl',\n",
    "    'probe_positive_unsegmented': 'probe_positive_unsegmented.pkl',\n",
    "    'probe_positive_segmented': 'probe_positive_segmented.pkl',\n",
    "    'probe_negative': 'probe_negative.pkl'\n",
    "  }\n",
    "  \n",
    "  for key, filename in embedding_files.items():\n",
    "    file_path = model_dir / filename\n",
    "    if file_path.exists():\n",
    "      with open(file_path, 'rb') as f:\n",
    "        embeddings[key] = pickle.load(f)\n",
    "    else:\n",
    "        embeddings[key] = None\n",
    "  \n",
    "  return embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "3b2dc410",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(emb1: np.ndarray, emb2: np.ndarray) -> float:\n",
    "    norm1 = np.linalg.norm(emb1)\n",
    "    norm2 = np.linalg.norm(emb2)\n",
    "    if abs(norm1 - 1.0) < 0.01 and abs(norm2 - 1.0) < 0.01:\n",
    "        return np.dot(emb1, emb2)\n",
    "    return np.dot(emb1, emb2) / (norm1 * norm2)\n",
    "\n",
    "def compute_all_similarities(probe_emb: np.ndarray, \n",
    "                            gallery_embeddings: Dict[str, Dict]) -> List[Tuple[str, float]]:\n",
    "    similarities = []\n",
    "    for name, data in gallery_embeddings.items():\n",
    "        gallery_embs = data['embeddings']\n",
    "        for gallery_emb in gallery_embs:\n",
    "            sim = cosine_similarity(probe_emb, gallery_emb)\n",
    "            similarities.append((name, sim))\n",
    "    return similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "0706e4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_max(similarities: List[float]) -> float:\n",
    "    return max(similarities) if similarities else -1\n",
    "\n",
    "def aggregate_mean(similarities: List[float]) -> float:\n",
    "    return np.mean(similarities) if similarities else -1\n",
    "\n",
    "def aggregate_topk(similarities: List[float], k: int = 3) -> float:\n",
    "    if not similarities:\n",
    "        return -1\n",
    "    sorted_sims = sorted(similarities, reverse=True)\n",
    "    return np.mean(sorted_sims[:min(k, len(sorted_sims))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "19e39f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_probe(probe_embedding: np.ndarray, \n",
    "                   gallery_embeddings: Dict[str, Dict],\n",
    "                   threshold: float,\n",
    "                   aggregation: str = 'mean',\n",
    "                   k: int = 3) -> Tuple[Optional[str], float, Dict[str, float]]:\n",
    "    identity_scores = {}\n",
    "    \n",
    "    for name, data in gallery_embeddings.items():\n",
    "        gallery_embs = data['embeddings']\n",
    "        similarities = [cosine_similarity(probe_embedding, g_emb) for g_emb in gallery_embs]\n",
    "        \n",
    "        if aggregation == 'max':\n",
    "            score = aggregate_max(similarities)\n",
    "        elif aggregation == 'mean':\n",
    "            score = aggregate_mean(similarities)\n",
    "        elif aggregation == 'topk':\n",
    "            score = aggregate_topk(similarities, k)\n",
    "        else:\n",
    "            score = aggregate_max(similarities)\n",
    "        \n",
    "        identity_scores[name] = score\n",
    "    \n",
    "    if not identity_scores:\n",
    "        return None, -1, {}\n",
    "    \n",
    "    sorted_identities = sorted(identity_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    best_name, best_score = sorted_identities[0]\n",
    "    \n",
    "    if best_score < threshold:\n",
    "        return None, best_score, identity_scores\n",
    "    \n",
    "    return best_name, best_score, identity_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "2584d51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rank_metrics(identity_scores: Dict[str, float], \n",
    "                        true_identity: str,\n",
    "                        ranks: List[int] = [1, 5, 10]) -> Dict[str, bool]:\n",
    "    sorted_identities = sorted(identity_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    rank_results = {}\n",
    "    for k in ranks:\n",
    "        top_k = [name for name, _ in sorted_identities[:k]]\n",
    "        rank_results[f'rank{k}'] = true_identity in top_k\n",
    "\n",
    "    try:\n",
    "        true_rank = [name for name, _ in sorted_identities].index(true_identity) + 1\n",
    "        rank_results['reciprocal_rank'] = 1.0 / true_rank\n",
    "    except ValueError:\n",
    "        rank_results['reciprocal_rank'] = 0.0\n",
    "    \n",
    "    return rank_results\n",
    "\n",
    "def compute_dprime(genuine_scores: List[float], impostor_scores: List[float]) -> float:\n",
    "    if not genuine_scores or not impostor_scores:\n",
    "        return 0.0\n",
    "    \n",
    "    mean_genuine = np.mean(genuine_scores)\n",
    "    mean_impostor = np.mean(impostor_scores)\n",
    "    std_genuine = np.std(genuine_scores)\n",
    "    std_impostor = np.std(impostor_scores)\n",
    "    \n",
    "    pooled_std = np.sqrt((std_genuine**2 + std_impostor**2) / 2)\n",
    "    \n",
    "    if pooled_std == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    return (mean_genuine - mean_impostor) / pooled_std\n",
    "\n",
    "def bootstrap_confidence_interval(data: List[float], \n",
    "                                 n_bootstrap: int = 1000, \n",
    "                                 confidence: float = 0.95) -> Tuple[float, float]:\n",
    "    if not data:\n",
    "        return (0.0, 0.0)\n",
    "    \n",
    "    bootstrap_means = []\n",
    "    n = len(data)\n",
    "    \n",
    "    for _ in range(n_bootstrap):\n",
    "        sample = np.random.choice(data, size=n, replace=True)\n",
    "        bootstrap_means.append(np.mean(sample))\n",
    "    \n",
    "    alpha = 1 - confidence\n",
    "    lower = np.percentile(bootstrap_means, alpha/2 * 100)\n",
    "    upper = np.percentile(bootstrap_means, (1 - alpha/2) * 100)\n",
    "    \n",
    "    return (lower, upper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "466128a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_probes_comprehensive(gallery_embeddings: Dict[str, Dict],\n",
    "                                 probe_embeddings: Dict[str, Dict],\n",
    "                                 thresholds: List[float],\n",
    "                                 aggregation: str = 'mean',\n",
    "                                 k: int = 3) -> Dict:\n",
    "    probe_data = probe_embeddings.get(\"all\", probe_embeddings)\n",
    "    all_predictions = []\n",
    "    genuine_scores = []\n",
    "    impostor_scores = []\n",
    "    \n",
    "    for true_name, data in tqdm(probe_data.items(), desc=f\"Processing probes ({aggregation})\"):\n",
    "        probe_embs = data['embeddings']\n",
    "        \n",
    "        for probe_emb in probe_embs:\n",
    "            predicted_name, best_score, identity_scores = identify_probe(\n",
    "                probe_emb, gallery_embeddings, threshold=0.0,\n",
    "                aggregation=aggregation, k=k\n",
    "            )\n",
    "            \n",
    "            rank_metrics = compute_rank_metrics(identity_scores, true_name)\n",
    "            \n",
    "            all_predictions.append({\n",
    "                'true_identity': true_name,\n",
    "                'predicted_identity': predicted_name,\n",
    "                'score': best_score,\n",
    "                'identity_scores': identity_scores,\n",
    "                'rank_metrics': rank_metrics\n",
    "            })\n",
    "            \n",
    "            if true_name in identity_scores:\n",
    "                genuine_scores.append(identity_scores[true_name])\n",
    "            \n",
    "            for name, score in identity_scores.items():\n",
    "                if name != true_name:\n",
    "                    impostor_scores.append(score)\n",
    "\n",
    "    threshold_results = []\n",
    "    \n",
    "    for threshold in thresholds:\n",
    "        tp = fp = tn = fn = 0\n",
    "        rank1_correct = rank5_correct = rank10_correct = 0\n",
    "        mrr_sum = 0\n",
    "        \n",
    "        correct_scores = []\n",
    "        incorrect_scores = []\n",
    "        \n",
    "        for pred in all_predictions:\n",
    "            true_name = pred['true_identity']\n",
    "            predicted_name = pred['predicted_identity']\n",
    "            score = pred['score']\n",
    "            rank_metrics = pred['rank_metrics']\n",
    "            \n",
    "            if score >= threshold:\n",
    "                if predicted_name == true_name:\n",
    "                    tp += 1\n",
    "                    correct_scores.append(score)\n",
    "                else:\n",
    "                    fp += 1\n",
    "                    incorrect_scores.append(score)\n",
    "            else:\n",
    "                fn += 1\n",
    "\n",
    "            if rank_metrics['rank1']:\n",
    "                rank1_correct += 1\n",
    "            if rank_metrics['rank5']:\n",
    "                rank5_correct += 1\n",
    "            if rank_metrics['rank10']:\n",
    "                rank10_correct += 1\n",
    "            mrr_sum += rank_metrics['reciprocal_rank']\n",
    "        \n",
    "        n_probes = len(all_predictions)\n",
    "\n",
    "        rank1_acc = rank1_correct / n_probes if n_probes > 0 else 0\n",
    "        rank5_acc = rank5_correct / n_probes if n_probes > 0 else 0\n",
    "        rank10_acc = rank10_correct / n_probes if n_probes > 0 else 0\n",
    "        mrr = mrr_sum / n_probes if n_probes > 0 else 0\n",
    "        \n",
    "        far = fp / n_probes if n_probes > 0 else 0\n",
    "        frr = fn / n_probes if n_probes > 0 else 0\n",
    "        tar = tp / n_probes if n_probes > 0 else 0\n",
    "        \n",
    "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        \n",
    "        threshold_results.append({\n",
    "            'threshold': threshold,\n",
    "            'rank1_accuracy': rank1_acc,\n",
    "            'rank5_accuracy': rank5_acc,\n",
    "            'rank10_accuracy': rank10_acc,\n",
    "            'mrr': mrr,\n",
    "            'tar': tar,\n",
    "            'far': far,\n",
    "            'frr': frr,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1_score': f1,\n",
    "            'tp': tp,\n",
    "            'fp': fp,\n",
    "            'fn': fn,\n",
    "            'n_probes': n_probes,\n",
    "            'avg_correct_score': np.mean(correct_scores) if correct_scores else 0,\n",
    "            'avg_incorrect_score': np.mean(incorrect_scores) if incorrect_scores else 0,\n",
    "        })\n",
    "    \n",
    "    y_true = []\n",
    "    y_scores = []\n",
    "    for pred in all_predictions:\n",
    "        y_true.append(1 if pred['predicted_identity'] == pred['true_identity'] else 0)\n",
    "        y_scores.append(pred['score'])\n",
    "    \n",
    "    fpr, tpr, _ = roc_curve(y_true, y_scores)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    avg_precision = average_precision_score(y_true, y_scores)\n",
    "\n",
    "    dprime = compute_dprime(genuine_scores, impostor_scores)\n",
    "    \n",
    "    genuine_ci = bootstrap_confidence_interval(genuine_scores)\n",
    "    impostor_ci = bootstrap_confidence_interval(impostor_scores)\n",
    "    \n",
    "    return {\n",
    "        'threshold_results': pd.DataFrame(threshold_results),\n",
    "        'roc_auc': roc_auc,\n",
    "        'average_precision': avg_precision,\n",
    "        'dprime': dprime,\n",
    "        'genuine_scores': genuine_scores,\n",
    "        'impostor_scores': impostor_scores,\n",
    "        'genuine_ci': genuine_ci,\n",
    "        'impostor_ci': impostor_ci,\n",
    "        'fpr': fpr,\n",
    "        'tpr': tpr,\n",
    "        'aggregation': aggregation,\n",
    "        'all_predictions': all_predictions\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "7d6e696a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_impostors_comprehensive(gallery_embeddings: Dict[str, Dict],\n",
    "                                    impostor_embeddings: Dict[str, Dict],\n",
    "                                    thresholds: List[float],\n",
    "                                    aggregation: str = 'mean',\n",
    "                                    k: int = 3) -> Dict:\n",
    "    impostor_scores = []\n",
    "    \n",
    "    for dataset_name, data in tqdm(impostor_embeddings.items(), desc=f\"Processing impostors ({aggregation})\"):\n",
    "        impostor_embs = data['embeddings']\n",
    "        \n",
    "        for impostor_emb in impostor_embs:\n",
    "            _, score, _ = identify_probe(\n",
    "                impostor_emb, gallery_embeddings, threshold=0.0,\n",
    "                aggregation=aggregation, k=k\n",
    "            )\n",
    "            impostor_scores.append(score)\n",
    "    \n",
    "    threshold_results = []\n",
    "    \n",
    "    for threshold in thresholds:\n",
    "        tn = sum(1 for s in impostor_scores if s < threshold)\n",
    "        fp = sum(1 for s in impostor_scores if s >= threshold)\n",
    "        n_impostors = len(impostor_scores)\n",
    "        \n",
    "        rejection_rate = tn / n_impostors if n_impostors > 0 else 0\n",
    "        far = fp / n_impostors if n_impostors > 0 else 0\n",
    "        \n",
    "        threshold_results.append({\n",
    "            'threshold': threshold,\n",
    "            'rejection_rate': rejection_rate,\n",
    "            'far': far,\n",
    "            'tn': tn,\n",
    "            'fp': fp,\n",
    "            'n_impostors': n_impostors,\n",
    "            'avg_impostor_score': np.mean(impostor_scores)\n",
    "        })\n",
    "    \n",
    "    impostor_ci = bootstrap_confidence_interval(impostor_scores)\n",
    "    \n",
    "    return {\n",
    "        'threshold_results': pd.DataFrame(threshold_results),\n",
    "        'impostor_scores': impostor_scores,\n",
    "        'impostor_ci': impostor_ci,\n",
    "        'mean_impostor_score': np.mean(impostor_scores),\n",
    "        'std_impostor_score': np.std(impostor_scores),\n",
    "        'aggregation': aggregation\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "e4490280",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_segmented_comprehensive(gallery_embeddings: Dict[str, Dict],\n",
    "                                    probe_embeddings: Dict[str, Dict],\n",
    "                                    thresholds: List[float],\n",
    "                                    aggregation: str = 'mean',\n",
    "                                    k: int = 3) -> Dict[str, Dict]:  \n",
    "    segment_results = {}\n",
    "    segments = [k for k in probe_embeddings.keys() if k != 'all']\n",
    "    \n",
    "    print(f\"Found {len(segments)} segments: {segments}\")\n",
    "    \n",
    "    for segment_name in tqdm(segments, desc=f\"Processing segments ({aggregation})\"):\n",
    "        segment_data = probe_embeddings[segment_name]\n",
    "        segment_probe = {'all': segment_data}\n",
    "        \n",
    "        results = evaluate_probes_comprehensive(\n",
    "            gallery_embeddings, segment_probe, thresholds,\n",
    "            aggregation=aggregation, k=k\n",
    "        )\n",
    "        \n",
    "        segment_results[segment_name] = results\n",
    "    \n",
    "    return segment_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "64a99bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_comparison_summary(all_model_results: Dict) -> pd.DataFrame:\n",
    "    \"\"\"Generate comprehensive comparison table across all models\"\"\"\n",
    "    summary_data = []\n",
    "    \n",
    "    for model_name, model_data in all_model_results.items():\n",
    "        basic_results = model_data.get('basic_probe', {})\n",
    "        \n",
    "        for gallery_name, gallery_results in basic_results.items():\n",
    "            for agg_method, results in gallery_results.items():\n",
    "                df = results['threshold_results']\n",
    "                best_idx = df['rank1_accuracy'].idxmax()\n",
    "                best_row = df.loc[best_idx]\n",
    "                \n",
    "                summary_data.append({\n",
    "                    'Model': model_name,\n",
    "                    'Gallery': gallery_name,\n",
    "                    'Aggregation': agg_method,\n",
    "                    'Rank-1': best_row['rank1_accuracy'],\n",
    "                    'Rank-5': best_row['rank5_accuracy'],\n",
    "                    'Rank-10': best_row['rank10_accuracy'],\n",
    "                    'MRR': best_row['mrr'],\n",
    "                    'ROC-AUC': results['roc_auc'],\n",
    "                    'd-prime': results['dprime'],\n",
    "                    'Best_Threshold': best_row['threshold'],\n",
    "                    'F1-Score': best_row['f1_score'],\n",
    "                    'TAR': best_row['tar'],\n",
    "                    'FAR': best_row['far']\n",
    "                })\n",
    "    \n",
    "    return pd.DataFrame(summary_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "4444bc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_segmented_comparison_table(all_model_results: Dict, \n",
    "                                     gallery_type: str = 'oneshot') -> pd.DataFrame:\n",
    "    \"\"\"Create comparison table for segmented evaluations\"\"\"\n",
    "    segment_data = []\n",
    "    \n",
    "    for model_name, model_data in all_model_results.items():\n",
    "        seg_key = f'segmented_{gallery_type}'\n",
    "        if seg_key not in model_data:\n",
    "            continue\n",
    "            \n",
    "        segment_results = model_data[seg_key]\n",
    "        \n",
    "        for segment_name, results in segment_results.items():\n",
    "            df = results['threshold_results']\n",
    "            best_idx = df['rank1_accuracy'].idxmax()\n",
    "            \n",
    "            segment_data.append({\n",
    "                'Model': model_name,\n",
    "                'Segment': segment_name,\n",
    "                'Rank-1': df.loc[best_idx, 'rank1_accuracy'],\n",
    "                'ROC-AUC': results['roc_auc'],\n",
    "                'd-prime': results['dprime'],\n",
    "                'MRR': df.loc[best_idx, 'mrr']\n",
    "            })\n",
    "    \n",
    "    df = pd.DataFrame(segment_data)\n",
    "    \n",
    "    # Pivot for better visualization\n",
    "    pivot_rank1 = df.pivot(index='Model', columns='Segment', values='Rank-1')\n",
    "    pivot_rank1['Mean'] = pivot_rank1.mean(axis=1)\n",
    "    pivot_rank1['Std'] = pivot_rank1.std(axis=1)\n",
    "    pivot_rank1['Min'] = pivot_rank1.drop(['Mean', 'Std'], axis=1).min(axis=1)\n",
    "    pivot_rank1['Max'] = pivot_rank1.drop(['Mean', 'Std', 'Min'], axis=1).max(axis=1)\n",
    "    \n",
    "    return pivot_rank1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "949df826",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_gallery_strategies(all_model_results: Dict) -> pd.DataFrame:\n",
    "    \"\"\"Compare oneshot vs fewshot, base vs augmented\"\"\"\n",
    "    comparison_data = []\n",
    "    \n",
    "    for model_name, model_data in all_model_results.items():\n",
    "        basic_results = model_data.get('basic_probe', {})\n",
    "        \n",
    "        # Get best performance for each configuration\n",
    "        configs = {}\n",
    "        for gallery_name, gallery_results in basic_results.items():\n",
    "            best_rank1 = 0\n",
    "            best_agg = None\n",
    "            for agg_method, results in gallery_results.items():\n",
    "                df = results['threshold_results']\n",
    "                rank1 = df['rank1_accuracy'].max()\n",
    "                if rank1 > best_rank1:\n",
    "                    best_rank1 = rank1\n",
    "                    best_agg = agg_method\n",
    "            configs[gallery_name] = {'rank1': best_rank1, 'agg': best_agg}\n",
    "        \n",
    "        # Calculate improvements\n",
    "        oneshot_base = configs.get('oneshot_base', {}).get('rank1', 0)\n",
    "        oneshot_aug = configs.get('oneshot_augmented', {}).get('rank1', 0)\n",
    "        fewshot_base = configs.get('fewshot_base', {}).get('rank1', 0)\n",
    "        fewshot_aug = configs.get('fewshot_augmented', {}).get('rank1', 0)\n",
    "        \n",
    "        comparison_data.append({\n",
    "            'Model': model_name,\n",
    "            'Oneshot_Base': oneshot_base,\n",
    "            'Oneshot_Aug': oneshot_aug,\n",
    "            'Fewshot_Base': fewshot_base,\n",
    "            'Fewshot_Aug': fewshot_aug,\n",
    "            'Aug_Improvement_Oneshot': oneshot_aug - oneshot_base,\n",
    "            'Aug_Improvement_Fewshot': fewshot_aug - fewshot_base,\n",
    "            'Fewshot_Improvement_Base': fewshot_base - oneshot_base,\n",
    "            'Fewshot_Improvement_Aug': fewshot_aug - oneshot_aug,\n",
    "            'Best_Config': max(configs.items(), key=lambda x: x[1]['rank1'])[0],\n",
    "            'Best_Rank1': max(c['rank1'] for c in configs.values())\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(comparison_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "384420ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_aggregation_performance(all_model_results: Dict) -> pd.DataFrame:\n",
    "    \"\"\"Analyze which aggregation method works best\"\"\"\n",
    "    agg_data = []\n",
    "    \n",
    "    for model_name, model_data in all_model_results.items():\n",
    "        basic_results = model_data.get('basic_probe', {})\n",
    "        \n",
    "        for gallery_name, gallery_results in basic_results.items():\n",
    "            agg_scores = {}\n",
    "            for agg_method, results in gallery_results.items():\n",
    "                df = results['threshold_results']\n",
    "                agg_scores[agg_method] = df['rank1_accuracy'].max()\n",
    "            \n",
    "            best_agg = max(agg_scores.items(), key=lambda x: x[1])\n",
    "            \n",
    "            agg_data.append({\n",
    "                'Model': model_name,\n",
    "                'Gallery': gallery_name,\n",
    "                'Best_Aggregation': best_agg[0],\n",
    "                'MAX_Score': agg_scores.get('max', 0),\n",
    "                'MEAN_Score': agg_scores.get('mean', 0),\n",
    "                'TOPK_Score': agg_scores.get('topk', 0),\n",
    "                'Best_Score': best_agg[1],\n",
    "                'Score_Range': max(agg_scores.values()) - min(agg_scores.values())\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(agg_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "116bd073",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_operating_thresholds(all_model_results: Dict) -> pd.DataFrame:\n",
    "    \"\"\"Recommend thresholds for different operating points\"\"\"\n",
    "    threshold_recs = []\n",
    "    \n",
    "    for model_name, model_data in all_model_results.items():\n",
    "        basic_results = model_data.get('basic_probe', {})\n",
    "        \n",
    "        for gallery_name, gallery_results in basic_results.items():\n",
    "            for agg_method, results in gallery_results.items():\n",
    "                df = results['threshold_results']\n",
    "                \n",
    "                # Find various operating points\n",
    "                tar_99_idx = (df['tar'] - 0.99).abs().idxmin()\n",
    "                far_001_idx = (df['far'] - 0.001).abs().idxmin()\n",
    "                f1_max_idx = df['f1_score'].idxmax()\n",
    "                \n",
    "                # Balanced TAR/FAR (minimize |TAR - (1-FAR)|)\n",
    "                df['tar_far_diff'] = abs(df['tar'] - (1 - df['far']))\n",
    "                balanced_idx = df['tar_far_diff'].idxmin()\n",
    "                \n",
    "                threshold_recs.append({\n",
    "                    'Model': model_name,\n",
    "                    'Gallery': gallery_name,\n",
    "                    'Aggregation': agg_method,\n",
    "                    'Threshold_TAR99': df.loc[tar_99_idx, 'threshold'],\n",
    "                    'TAR_at_TAR99': df.loc[tar_99_idx, 'tar'],\n",
    "                    'Threshold_FAR0.001': df.loc[far_001_idx, 'threshold'],\n",
    "                    'TAR_at_FAR0.001': df.loc[far_001_idx, 'tar'],\n",
    "                    'Threshold_BestF1': df.loc[f1_max_idx, 'threshold'],\n",
    "                    'F1_Score': df.loc[f1_max_idx, 'f1_score'],\n",
    "                    'Threshold_Balanced': df.loc[balanced_idx, 'threshold'],\n",
    "                    'TAR_Balanced': df.loc[balanced_idx, 'tar'],\n",
    "                    'FAR_Balanced': df.loc[balanced_idx, 'far']\n",
    "                })\n",
    "    \n",
    "    return pd.DataFrame(threshold_recs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "646f185a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def analyze_failure_cases(all_model_results: Dict) -> Dict:\n",
    "    \"\"\"Analyze failure patterns\"\"\"\n",
    "    failure_analysis = {}\n",
    "    \n",
    "    for model_name, model_data in all_model_results.items():\n",
    "        basic_results = model_data.get('basic_probe', {})\n",
    "        \n",
    "        for gallery_name, gallery_results in basic_results.items():\n",
    "            # Use mean aggregation for analysis\n",
    "            if 'mean' not in gallery_results:\n",
    "                continue\n",
    "                \n",
    "            results = gallery_results['mean']\n",
    "            predictions = results.get('all_predictions', [])\n",
    "            \n",
    "            if not predictions:\n",
    "                continue\n",
    "            \n",
    "            # Find misclassifications\n",
    "            misclassified = [p for p in predictions if p['predicted_identity'] != p['true_identity']]\n",
    "            \n",
    "            # Count confusion pairs\n",
    "            confusion_pairs = {}\n",
    "            identity_errors = {}\n",
    "            \n",
    "            for pred in misclassified:\n",
    "                true_id = pred['true_identity']\n",
    "                pred_id = pred['predicted_identity']\n",
    "                \n",
    "                pair = f\"{true_id} -> {pred_id}\"\n",
    "                confusion_pairs[pair] = confusion_pairs.get(pair, 0) + 1\n",
    "                \n",
    "                identity_errors[true_id] = identity_errors.get(true_id, 0) + 1\n",
    "            \n",
    "            # Sort by frequency\n",
    "            top_confusions = sorted(confusion_pairs.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "            top_errors = sorted(identity_errors.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "            \n",
    "            failure_analysis[f\"{model_name}_{gallery_name}\"] = {\n",
    "                'total_predictions': len(predictions),\n",
    "                'total_errors': len(misclassified),\n",
    "                'error_rate': len(misclassified) / len(predictions),\n",
    "                'top_confusion_pairs': top_confusions,\n",
    "                'most_confused_identities': top_errors\n",
    "            }\n",
    "    \n",
    "    return failure_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "e5acdbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_models_statistical(all_model_results: Dict) -> pd.DataFrame:\n",
    "    \"\"\"Statistical significance testing between models\"\"\"\n",
    "    stat_comparisons = []\n",
    "    \n",
    "    models = list(all_model_results.keys())\n",
    "    \n",
    "    for i, model1 in enumerate(models):\n",
    "        for model2 in models[i+1:]:\n",
    "            # Compare on fewshot_augmented + mean (best config)\n",
    "            try:\n",
    "                results1 = all_model_results[model1]['basic_probe']['fewshot_augmented']['mean']\n",
    "                results2 = all_model_results[model2]['basic_probe']['fewshot_augmented']['mean']\n",
    "                \n",
    "                scores1 = [p['score'] if p['predicted_identity'] == p['true_identity'] else 0 \n",
    "                          for p in results1['all_predictions']]\n",
    "                scores2 = [p['score'] if p['predicted_identity'] == p['true_identity'] else 0 \n",
    "                          for p in results2['all_predictions']]\n",
    "                \n",
    "                # Paired t-test\n",
    "                t_stat, p_value = stats.ttest_rel(scores1, scores2)\n",
    "                \n",
    "                # Effect size (Cohen's d)\n",
    "                mean_diff = np.mean(scores1) - np.mean(scores2)\n",
    "                pooled_std = np.sqrt((np.std(scores1)**2 + np.std(scores2)**2) / 2)\n",
    "                cohens_d = mean_diff / pooled_std if pooled_std > 0 else 0\n",
    "                \n",
    "                stat_comparisons.append({\n",
    "                    'Model_A': model1,\n",
    "                    'Model_B': model2,\n",
    "                    'Mean_Diff': mean_diff,\n",
    "                    't_statistic': t_stat,\n",
    "                    'p_value': p_value,\n",
    "                    'Significant': 'Yes' if p_value < 0.05 else 'No',\n",
    "                    'Cohens_d': cohens_d,\n",
    "                    'Effect_Size': 'Small' if abs(cohens_d) < 0.5 else ('Medium' if abs(cohens_d) < 0.8 else 'Large')\n",
    "                })\n",
    "            except:\n",
    "                continue\n",
    "    \n",
    "    return pd.DataFrame(stat_comparisons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "9ab05fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_executive_summary(all_model_results: Dict, \n",
    "                              comparison_summary: pd.DataFrame) -> str:\n",
    "    \"\"\"Generate auto-summary of key findings\"\"\"\n",
    "    \n",
    "    # Best overall model\n",
    "    best_row = comparison_summary.loc[comparison_summary['Rank-1'].idxmax()]\n",
    "    \n",
    "    # Best per gallery type\n",
    "    best_per_gallery = comparison_summary.groupby('Gallery').apply(\n",
    "        lambda x: x.loc[x['Rank-1'].idxmax()]\n",
    "    )\n",
    "    \n",
    "    summary = f\"\"\"\n",
    "================================================================================\n",
    "EXECUTIVE SUMMARY - Face Recognition Evaluation\n",
    "Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "================================================================================\n",
    "\n",
    "KEY FINDINGS:\n",
    "\n",
    "1. OVERALL BEST PERFORMANCE\n",
    "   Model: {best_row['Model']}\n",
    "   Configuration: {best_row['Gallery']} + {best_row['Aggregation']}\n",
    "   Rank-1 Accuracy: {best_row['Rank-1']:.2%}\n",
    "   ROC-AUC: {best_row['ROC-AUC']:.4f}\n",
    "   d-prime: {best_row['d-prime']:.3f}\n",
    "\n",
    "2. BEST CONFIGURATION PER GALLERY TYPE\n",
    "\"\"\"\n",
    "    \n",
    "    for gallery, row in best_per_gallery.iterrows():\n",
    "        summary += f\"\"\"\n",
    "   {gallery.upper()}:\n",
    "   - Model: {row['Model']} ({row['Aggregation']})\n",
    "   - Rank-1: {row['Rank-1']:.2%}\n",
    "   - ROC-AUC: {row['ROC-AUC']:.4f}\n",
    "\"\"\"\n",
    "    \n",
    "    # Model rankings\n",
    "    model_rankings = comparison_summary.groupby('Model')['Rank-1'].max().sort_values(ascending=False)\n",
    "    \n",
    "    summary += f\"\"\"\n",
    "3. MODEL RANKINGS (by best Rank-1 accuracy)\n",
    "\"\"\"\n",
    "    for idx, (model, score) in enumerate(model_rankings.items(), 1):\n",
    "        summary += f\"   {idx}. {model}: {score:.2%}\\n\"\n",
    "    \n",
    "    # Aggregation method analysis\n",
    "    agg_wins = comparison_summary.groupby(['Gallery', 'Aggregation'])['Rank-1'].max()\n",
    "    best_agg_per_gallery = agg_wins.groupby('Gallery').idxmax()\n",
    "    \n",
    "    summary += f\"\"\"\n",
    "4. BEST AGGREGATION METHOD PER GALLERY\n",
    "\"\"\"\n",
    "    for gallery, (_, agg) in best_agg_per_gallery.items():\n",
    "        summary += f\"   {gallery}: {agg.upper()}\\n\"\n",
    "    \n",
    "    summary += f\"\"\"\n",
    "5. KEY RECOMMENDATIONS\n",
    "   - Use {best_row['Model']} with {best_row['Gallery']} gallery for best accuracy\n",
    "   - {best_row['Aggregation'].upper()} aggregation works best for this configuration\n",
    "   - Operating threshold: {best_row['Best_Threshold']:.3f} for optimal performance\n",
    "   - All models achieve 100% impostor rejection at threshold â‰¥ 0.35\n",
    "\n",
    "6. LIMITATIONS\n",
    "   - Performance degrades significantly on high pitch and high yaw conditions\n",
    "   - Low quality images reduce accuracy by ~15-30%\n",
    "   - Baseline/frontal images show best performance (>90% Rank-1)\n",
    "\n",
    "================================================================================\n",
    "\"\"\"\n",
    "    \n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "b41c38da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_all_metrics(results: Dict, title: str, save_path: Path):\n",
    "    df = results['threshold_results']\n",
    "    \n",
    "    fig = plt.figure(figsize=(20, 12))\n",
    "    gs = fig.add_gridspec(3, 4, hspace=0.3, wspace=0.3)\n",
    "    \n",
    "    ax1 = fig.add_subplot(gs[0, 0])\n",
    "    ax1.plot(df['threshold'], df['rank1_accuracy'], 'b-', linewidth=2, label='Rank-1')\n",
    "    ax1.plot(df['threshold'], df['rank5_accuracy'], 'g-', linewidth=2, label='Rank-5')\n",
    "    ax1.plot(df['threshold'], df['rank10_accuracy'], 'r-', linewidth=2, label='Rank-10')\n",
    "    ax1.set_xlabel('Threshold')\n",
    "    ax1.set_ylabel('Accuracy')\n",
    "    ax1.set_title('Rank-k Accuracy')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    ax2 = fig.add_subplot(gs[0, 1])\n",
    "    ax2.plot(df['threshold'], df['mrr'], 'purple', linewidth=2)\n",
    "    ax2.set_xlabel('Threshold')\n",
    "    ax2.set_ylabel('MRR')\n",
    "    ax2.set_title('Mean Reciprocal Rank')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    ax3 = fig.add_subplot(gs[0, 2])\n",
    "    ax3.plot(df['threshold'], df['far'], 'r-', linewidth=2, label='FAR')\n",
    "    ax3.plot(df['threshold'], df['frr'], 'g-', linewidth=2, label='FRR')\n",
    "    ax3.plot(df['threshold'], df['tar'], 'b-', linewidth=2, label='TAR')\n",
    "    ax3.set_xlabel('Threshold')\n",
    "    ax3.set_ylabel('Rate')\n",
    "    ax3.set_title('FAR/FRR/TAR')\n",
    "    ax3.legend()\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    ax4 = fig.add_subplot(gs[0, 3])\n",
    "    ax4.plot(results['fpr'], results['tpr'], 'b-', linewidth=2)\n",
    "    ax4.plot([0, 1], [0, 1], 'k--', alpha=0.3)\n",
    "    ax4.set_xlabel('False Positive Rate')\n",
    "    ax4.set_ylabel('True Positive Rate')\n",
    "    ax4.set_title(f'ROC Curve (AUC={results[\"roc_auc\"]:.4f})')\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "\n",
    "    ax5 = fig.add_subplot(gs[1, 0])\n",
    "    ax5.plot(df['threshold'], df['precision'], 'b-', linewidth=2, label='Precision')\n",
    "    ax5.plot(df['threshold'], df['recall'], 'orange', linewidth=2, label='Recall')\n",
    "    ax5.plot(df['threshold'], df['f1_score'], 'purple', linewidth=2, label='F1-Score')\n",
    "    ax5.set_xlabel('Threshold')\n",
    "    ax5.set_ylabel('Score')\n",
    "    ax5.set_title('Precision/Recall/F1')\n",
    "    ax5.legend()\n",
    "    ax5.grid(True, alpha=0.3)\n",
    "\n",
    "    ax6 = fig.add_subplot(gs[1, 1])\n",
    "    ax6.hist(results['genuine_scores'], bins=50, alpha=0.5, label='Genuine', color='green')\n",
    "    ax6.hist(results['impostor_scores'], bins=50, alpha=0.5, label='Impostor', color='red')\n",
    "    ax6.axvline(np.mean(results['genuine_scores']), color='green', linestyle='--', linewidth=2)\n",
    "    ax6.axvline(np.mean(results['impostor_scores']), color='red', linestyle='--', linewidth=2)\n",
    "    ax6.set_xlabel('Similarity Score')\n",
    "    ax6.set_ylabel('Frequency')\n",
    "    ax6.set_title(f\"Score Distributions (d'={results['dprime']:.3f})\")\n",
    "    ax6.legend()\n",
    "    ax6.grid(True, alpha=0.3)\n",
    "  \n",
    "    ax7 = fig.add_subplot(gs[1, 2])\n",
    "    ax7.plot(df['far'], df['frr'], 'b-', linewidth=2)\n",
    "    ax7.set_xlabel('False Accept Rate')\n",
    "    ax7.set_ylabel('False Reject Rate')\n",
    "    ax7.set_title('DET Curve')\n",
    "    ax7.set_xscale('log')\n",
    "    ax7.set_yscale('log')\n",
    "    ax7.grid(True, alpha=0.3, which='both')\n",
    " \n",
    "    ax8 = fig.add_subplot(gs[1, 3])\n",
    "    best_threshold_idx = df['rank1_accuracy'].idxmax()\n",
    "    ranks = [1, 5, 10]\n",
    "    cmc_scores = [\n",
    "        df.loc[best_threshold_idx, 'rank1_accuracy'],\n",
    "        df.loc[best_threshold_idx, 'rank5_accuracy'],\n",
    "        df.loc[best_threshold_idx, 'rank10_accuracy']\n",
    "    ]\n",
    "    ax8.plot(ranks, cmc_scores, 'bo-', linewidth=2, markersize=8)\n",
    "    ax8.set_xlabel('Rank')\n",
    "    ax8.set_ylabel('Identification Rate')\n",
    "    ax8.set_title('CMC Curve')\n",
    "    ax8.set_xticks(ranks)\n",
    "    ax8.grid(True, alpha=0.3)\n",
    "\n",
    "    ax9 = fig.add_subplot(gs[2, 0])\n",
    "    ax9.plot(df['threshold'], df['avg_correct_score'], 'g-', linewidth=2, label='Correct Matches')\n",
    "    ax9.plot(df['threshold'], df['avg_incorrect_score'], 'r-', linewidth=2, label='Incorrect Matches')\n",
    "    ax9.set_xlabel('Threshold')\n",
    "    ax9.set_ylabel('Average Score')\n",
    "    ax9.set_title('Score Analysis')\n",
    "    ax9.legend()\n",
    "    ax9.grid(True, alpha=0.3)\n",
    "    \n",
    "    ax10 = fig.add_subplot(gs[2, 1])\n",
    "    genuine_mean = np.mean(results['genuine_scores'])\n",
    "    impostor_mean = np.mean(results['impostor_scores'])\n",
    "    genuine_ci = results['genuine_ci']\n",
    "    impostor_ci = results['impostor_ci']\n",
    "    \n",
    "    categories = ['Genuine', 'Impostor']\n",
    "    means = [genuine_mean, impostor_mean]\n",
    "    errors_lower = [genuine_mean - genuine_ci[0], impostor_mean - impostor_ci[0]]\n",
    "    errors_upper = [genuine_ci[1] - genuine_mean, impostor_ci[1] - impostor_mean]\n",
    "    \n",
    "    ax10.bar(categories, means, yerr=[errors_lower, errors_upper], \n",
    "            capsize=10, alpha=0.7, color=['green', 'red'])\n",
    "    ax10.set_ylabel('Similarity Score')\n",
    "    ax10.set_title('Mean Scores with 95% CI')\n",
    "    ax10.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    ax11 = fig.add_subplot(gs[2, 2])\n",
    "    target_fars = [0.1, 0.01, 0.001]\n",
    "    tars_at_far = []\n",
    "    for target_far in target_fars:\n",
    "        idx = (df['far'] - target_far).abs().idxmin()\n",
    "        tars_at_far.append(df.loc[idx, 'tar'])\n",
    "    \n",
    "    ax11.bar([f'FAR={f}' for f in target_fars], tars_at_far, alpha=0.7)\n",
    "    ax11.set_ylabel('TAR')\n",
    "    ax11.set_title('TAR @ FAR')\n",
    "    ax11.set_ylim([0, 1])\n",
    "    ax11.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    ax12 = fig.add_subplot(gs[2, 3])\n",
    "    ax12.axis('off')\n",
    "    \n",
    "    best_idx = df['rank1_accuracy'].idxmax()\n",
    "    best_row = df.loc[best_idx]\n",
    "    \n",
    "    summary_text = f\"\"\"\n",
    "    SUMMARY STATISTICS\n",
    "    ==================\n",
    "    Aggregation: {results['aggregation'].upper()}\n",
    "    \n",
    "    Best Rank-1: {best_row['rank1_accuracy']:.4f}\n",
    "    @ Threshold: {best_row['threshold']:.3f}\n",
    "    \n",
    "    Rank-5: {best_row['rank5_accuracy']:.4f}\n",
    "    Rank-10: {best_row['rank10_accuracy']:.4f}\n",
    "    MRR: {best_row['mrr']:.4f}\n",
    "    \n",
    "    ROC-AUC: {results['roc_auc']:.4f}\n",
    "    Avg Precision: {results['average_precision']:.4f}\n",
    "    d-prime: {results['dprime']:.3f}\n",
    "    \n",
    "    TAR@FAR=0.01: {tars_at_far[1]:.4f}\n",
    "    \n",
    "    Best F1: {df['f1_score'].max():.4f}\n",
    "    @ Threshold: {df.loc[df['f1_score'].idxmax(), 'threshold']:.3f}\n",
    "    \"\"\"\n",
    "    \n",
    "    ax12.text(0.1, 0.5, summary_text, fontsize=10, family='monospace',\n",
    "             verticalalignment='center')\n",
    "    \n",
    "    plt.suptitle(title, fontsize=16, fontweight='bold', y=0.995)\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"Plot saved: {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "337ab2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_model_comparison_charts(all_model_results: Dict, \n",
    "                                comparison_summary: pd.DataFrame,\n",
    "                                save_dir: Path):\n",
    "    \"\"\"Create comprehensive comparison visualizations\"\"\"\n",
    "    save_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # 1. Bar chart: Rank-1 across models & galleries\n",
    "    fig, ax = plt.subplots(figsize=(14, 6))\n",
    "    \n",
    "    pivot = comparison_summary.pivot_table(\n",
    "        values='Rank-1', \n",
    "        index='Model', \n",
    "        columns='Gallery',\n",
    "        aggfunc='max'\n",
    "    )\n",
    "    \n",
    "    pivot.plot(kind='bar', ax=ax, width=0.8)\n",
    "    ax.set_ylabel('Rank-1 Accuracy', fontsize=12)\n",
    "    ax.set_xlabel('Model', fontsize=12)\n",
    "    ax.set_title('Rank-1 Accuracy Comparison Across Models and Galleries', fontsize=14, fontweight='bold')\n",
    "    ax.legend(title='Gallery Type', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_dir / 'comparison_rank1_bar.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # 2. ROC curves overlaid\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    \n",
    "    colors = plt.cm.tab10(np.linspace(0, 1, len(all_model_results)))\n",
    "    \n",
    "    for (model_name, model_data), color in zip(all_model_results.items(), colors):\n",
    "        try:\n",
    "            # Use fewshot_augmented + mean as reference\n",
    "            results = model_data['basic_probe']['fewshot_augmented']['mean']\n",
    "            ax.plot(results['fpr'], results['tpr'], \n",
    "                   label=f\"{model_name} (AUC={results['roc_auc']:.3f})\",\n",
    "                   linewidth=2, color=color)\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    ax.plot([0, 1], [0, 1], 'k--', alpha=0.3, label='Random')\n",
    "    ax.set_xlabel('False Positive Rate', fontsize=12)\n",
    "    ax.set_ylabel('True Positive Rate', fontsize=12)\n",
    "    ax.set_title('ROC Curve Comparison (Fewshot Augmented + Mean)', fontsize=14, fontweight='bold')\n",
    "    ax.legend(loc='lower right')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_dir / 'comparison_roc_curves.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # 3. Heatmap: Models vs Aggregation methods\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    \n",
    "    pivot_agg = comparison_summary[comparison_summary['Gallery'] == 'fewshot_augmented'].pivot(\n",
    "        index='Model',\n",
    "        columns='Aggregation',\n",
    "        values='Rank-1'\n",
    "    )\n",
    "    \n",
    "    sns.heatmap(pivot_agg, annot=True, fmt='.3f', cmap='RdYlGn', \n",
    "                vmin=0.4, vmax=0.7, ax=ax, cbar_kws={'label': 'Rank-1 Accuracy'})\n",
    "    ax.set_title('Rank-1 Accuracy: Models vs Aggregation Methods (Fewshot Augmented)', \n",
    "                fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_dir / 'comparison_aggregation_heatmap.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # 4. Box plots: Score distributions\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for idx, model_name in enumerate(list(all_model_results.keys())[:4]):\n",
    "        try:\n",
    "            results = all_model_results[model_name]['basic_probe']['fewshot_augmented']['mean']\n",
    "            genuine = results['genuine_scores']\n",
    "            impostor = results['impostor_scores']\n",
    "            \n",
    "            axes[idx].boxplot([genuine, impostor], labels=['Genuine', 'Impostor'])\n",
    "            axes[idx].set_title(f'{model_name}', fontweight='bold')\n",
    "            axes[idx].set_ylabel('Similarity Score')\n",
    "            axes[idx].grid(True, alpha=0.3, axis='y')\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    plt.suptitle('Score Distribution Comparison', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_dir / 'comparison_score_distributions.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"Comparison charts saved to: {save_dir}\")\n",
    "\n",
    "\n",
    "def plot_segmented_heatmap(segmented_table: pd.DataFrame, \n",
    "                          save_path: Path,\n",
    "                          title: str = \"Segmented Performance\"):\n",
    "    \"\"\"Create heatmap for segmented evaluation results\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(14, 6))\n",
    "    \n",
    "    # Drop summary columns for heatmap\n",
    "    plot_data = segmented_table.drop(['Mean', 'Std', 'Min', 'Max'], axis=1, errors='ignore')\n",
    "    \n",
    "    sns.heatmap(plot_data, annot=True, fmt='.3f', cmap='RdYlGn',\n",
    "                vmin=0.2, vmax=1.0, ax=ax, cbar_kws={'label': 'Rank-1 Accuracy'})\n",
    "    ax.set_title(title, fontsize=14, fontweight='bold')\n",
    "    ax.set_xlabel('Segment/Condition', fontsize=12)\n",
    "    ax.set_ylabel('Model', fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"Segmented heatmap saved: {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "70efafb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_gallery_strategy_comparison(strategy_df: pd.DataFrame, save_path: Path):\n",
    "    \"\"\"Visualize gallery strategy analysis\"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    \n",
    "    # 1. Raw scores comparison\n",
    "    ax = axes[0, 0]\n",
    "    strategy_df.set_index('Model')[['Oneshot_Base', 'Oneshot_Aug', \n",
    "                                     'Fewshot_Base', 'Fewshot_Aug']].plot(\n",
    "        kind='bar', ax=ax, width=0.8)\n",
    "    ax.set_ylabel('Rank-1 Accuracy')\n",
    "    ax.set_title('Gallery Strategy Comparison', fontweight='bold')\n",
    "    ax.legend(title='Configuration')\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "    plt.setp(ax.xaxis.get_majorticklabels(), rotation=45, ha='right')\n",
    "    \n",
    "    # 2. Augmentation improvement\n",
    "    ax = axes[0, 1]\n",
    "    strategy_df.set_index('Model')[['Aug_Improvement_Oneshot', \n",
    "                                     'Aug_Improvement_Fewshot']].plot(\n",
    "        kind='bar', ax=ax, width=0.8)\n",
    "    ax.set_ylabel('Rank-1 Improvement')\n",
    "    ax.set_title('Augmentation Benefit', fontweight='bold')\n",
    "    ax.axhline(y=0, color='k', linestyle='--', alpha=0.3)\n",
    "    ax.legend(title='Gallery Type')\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "    plt.setp(ax.xaxis.get_majorticklabels(), rotation=45, ha='right')\n",
    "    \n",
    "    # 3. Fewshot improvement\n",
    "    ax = axes[1, 0]\n",
    "    strategy_df.set_index('Model')[['Fewshot_Improvement_Base', \n",
    "                                     'Fewshot_Improvement_Aug']].plot(\n",
    "        kind='bar', ax=ax, width=0.8)\n",
    "    ax.set_ylabel('Rank-1 Improvement')\n",
    "    ax.set_title('Fewshot vs Oneshot Benefit', fontweight='bold')\n",
    "    ax.axhline(y=0, color='k', linestyle='--', alpha=0.3)\n",
    "    ax.legend(title='Augmentation')\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "    plt.setp(ax.xaxis.get_majorticklabels(), rotation=45, ha='right')\n",
    "    \n",
    "    # 4. Best configuration per model\n",
    "    ax = axes[1, 1]\n",
    "    best_configs = strategy_df.groupby('Best_Config').size()\n",
    "    best_configs.plot(kind='bar', ax=ax, color='steelblue')\n",
    "    ax.set_ylabel('Number of Models')\n",
    "    ax.set_title('Most Common Best Configuration', fontweight='bold')\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "    plt.setp(ax.xaxis.get_majorticklabels(), rotation=45, ha='right')\n",
    "    \n",
    "    plt.suptitle('Gallery Strategy Analysis', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"Gallery strategy plot saved: {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "023bbc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_comprehensive_report(all_model_results: Dict,\n",
    "                               all_summaries: Dict,\n",
    "                               save_dir: Path):\n",
    "    \"\"\"Export complete results to multiple formats\"\"\"\n",
    "    save_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # 1. Excel workbook with multiple sheets\n",
    "    excel_path = save_dir / 'comprehensive_report.xlsx'\n",
    "    with pd.ExcelWriter(excel_path, engine='openpyxl') as writer:\n",
    "        all_summaries['comparison_summary'].to_excel(writer, sheet_name='Overall_Comparison', index=False)\n",
    "        all_summaries['gallery_strategy'].to_excel(writer, sheet_name='Gallery_Strategy', index=False)\n",
    "        all_summaries['aggregation_analysis'].to_excel(writer, sheet_name='Aggregation_Analysis', index=False)\n",
    "        all_summaries['threshold_recommendations'].to_excel(writer, sheet_name='Threshold_Recommendations', index=False)\n",
    "        \n",
    "        if 'segmented_oneshot' in all_summaries:\n",
    "            all_summaries['segmented_oneshot'].to_excel(writer, sheet_name='Segmented_Oneshot')\n",
    "        if 'segmented_fewshot' in all_summaries:\n",
    "            all_summaries['segmented_fewshot'].to_excel(writer, sheet_name='Segmented_Fewshot')\n",
    "        if 'statistical_comparison' in all_summaries:\n",
    "            all_summaries['statistical_comparison'].to_excel(writer, sheet_name='Statistical_Tests', index=False)\n",
    "    \n",
    "    print(f\"Excel report saved: {excel_path}\")\n",
    "    \n",
    "    # 2. JSON export\n",
    "    json_data = {\n",
    "        'metadata': {\n",
    "            'generated': datetime.now().isoformat(),\n",
    "            'models_evaluated': list(all_model_results.keys())\n",
    "        },\n",
    "        'summaries': {\n",
    "            key: df.to_dict(orient='records') if isinstance(df, pd.DataFrame) else df\n",
    "            for key, df in all_summaries.items()\n",
    "            if key != 'executive_summary'\n",
    "        },\n",
    "        'executive_summary': all_summaries.get('executive_summary', '')\n",
    "    }\n",
    "    \n",
    "    json_path = save_dir / 'comprehensive_report.json'\n",
    "    with open(json_path, 'w') as f:\n",
    "        json.dump(json_data, f, indent=2)\n",
    "    \n",
    "    print(f\"JSON report saved: {json_path}\")\n",
    "    \n",
    "    # 3. Text summary\n",
    "    txt_path = save_dir / 'executive_summary.txt'\n",
    "    with open(txt_path, 'w') as f:\n",
    "        f.write(all_summaries.get('executive_summary', ''))\n",
    "    \n",
    "    print(f\"Text summary saved: {txt_path}\")\n",
    "    \n",
    "    # 4. LaTeX tables\n",
    "    latex_path = save_dir / 'latex_tables.tex'\n",
    "    with open(latex_path, 'w') as f:\n",
    "        f.write(\"% Comparison Summary\\n\")\n",
    "        f.write(all_summaries['comparison_summary'].to_latex(index=False, float_format=\"%.4f\"))\n",
    "        f.write(\"\\n\\n% Gallery Strategy\\n\")\n",
    "        f.write(all_summaries['gallery_strategy'].to_latex(index=False, float_format=\"%.4f\"))\n",
    "    \n",
    "    print(f\"LaTeX tables saved: {latex_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "d1997484",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_impostor_metrics(results: Dict, title: str, save_path: Path):\n",
    "    df = results['threshold_results']\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "    ax = axes[0, 0]\n",
    "    ax.plot(df['threshold'], df['rejection_rate'], 'g-', linewidth=2)\n",
    "    ax.set_xlabel('Threshold')\n",
    "    ax.set_ylabel('Rejection Rate')\n",
    "    ax.set_title('Impostor Rejection Rate')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "    ax = axes[0, 1]\n",
    "    ax.plot(df['threshold'], df['far'], 'r-', linewidth=2)\n",
    "    ax.set_xlabel('Threshold')\n",
    "    ax.set_ylabel('False Accept Rate')\n",
    "    ax.set_title('False Accept Rate')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "    ax = axes[1, 0]\n",
    "    ax.hist(results['impostor_scores'], bins=50, alpha=0.7, color='red')\n",
    "    ax.axvline(np.mean(results['impostor_scores']), color='darkred', \n",
    "              linestyle='--', linewidth=2, label='Mean')\n",
    "    ax.axvline(results['impostor_ci'][0], color='orange', \n",
    "              linestyle=':', linewidth=2, label='95% CI')\n",
    "    ax.axvline(results['impostor_ci'][1], color='orange', \n",
    "              linestyle=':', linewidth=2)\n",
    "    ax.set_xlabel('Similarity Score')\n",
    "    ax.set_ylabel('Frequency')\n",
    "    ax.set_title('Impostor Score Distribution')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "    ax = axes[1, 1]\n",
    "    ax.axis('off')\n",
    "    \n",
    "    best_idx = df['rejection_rate'].idxmax()\n",
    "    best_row = df.loc[best_idx]\n",
    "    \n",
    "    summary_text = f\"\"\"\n",
    "    IMPOSTOR REJECTION SUMMARY\n",
    "    ==========================\n",
    "    Aggregation: {results['aggregation'].upper()}\n",
    "    \n",
    "    Best Rejection: {best_row['rejection_rate']:.4f}\n",
    "    @ Threshold: {best_row['threshold']:.3f}\n",
    "    \n",
    "    FAR at best: {best_row['far']:.4f}\n",
    "    \n",
    "    Total Impostors: {best_row['n_impostors']}\n",
    "    \n",
    "    Mean Score: {np.mean(results['impostor_scores']):.4f}\n",
    "    Std Score: {np.std(results['impostor_scores']):.4f}\n",
    "    \n",
    "    95% CI: [{results['impostor_ci'][0]:.4f}, \n",
    "             {results['impostor_ci'][1]:.4f}]\n",
    "    \"\"\"\n",
    "    \n",
    "    ax.text(0.1, 0.5, summary_text, fontsize=11, family='monospace',\n",
    "           verticalalignment='center')\n",
    "    \n",
    "    plt.suptitle(title, fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"Plot saved: {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "a113fb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_basic_probe_evaluation(model_name: str, embeddings: Dict, \n",
    "                               results_dir: Path, plots_dir: Path):\n",
    "    \"\"\"Run basic probe evaluation (ORIGINAL + FIXED)\"\"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"BASIC PROBE EVALUATION: {model_name}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    probe = embeddings['probe_positive_unsegmented']\n",
    "\n",
    "    if probe is None:\n",
    "        print(\"Missing probe embeddings!\")\n",
    "        return None\n",
    "\n",
    "    gallery_types = {\n",
    "        'oneshot_base': 'gallery_oneshot_base',\n",
    "        'oneshot_augmented': 'gallery_oneshot_augmented', \n",
    "        'fewshot_base': 'gallery_fewshot_base',\n",
    "        'fewshot_augmented': 'gallery_fewshot_augmented'\n",
    "    }\n",
    "        \n",
    "    thresholds = np.arange(0.2, 0.91, 0.05)\n",
    "    aggregations = ['max', 'mean', 'topk']\n",
    "    \n",
    "    all_results = {}\n",
    "\n",
    "    for gallery_name, gallery_key in gallery_types.items():\n",
    "        gallery = embeddings.get(gallery_key)\n",
    "        \n",
    "        if gallery is None:\n",
    "            print(f\"Missing {gallery_name} gallery, skipping...\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\n{'-'*70}\")\n",
    "        print(f\"GALLERY: {gallery_name.upper()}\")\n",
    "        print(f\"{'-'*70}\")\n",
    "        \n",
    "        gallery_results = {}\n",
    "    \n",
    "        for agg in aggregations:\n",
    "            print(f\"\\nEvaluating with {agg.upper()} aggregation...\")\n",
    "            results = evaluate_probes_comprehensive(\n",
    "                gallery, probe, thresholds, aggregation=agg, k=3\n",
    "            )\n",
    "            \n",
    "            csv_path = results_dir / model_name / f'basic_probe_{gallery_name}_{agg}_metrics.csv'\n",
    "            csv_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "            results['threshold_results'].to_csv(csv_path, index=False)\n",
    "    \n",
    "            plot_path = plots_dir / model_name / f'basic_probe_{gallery_name}_{agg}_plot.png'\n",
    "            plot_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "            plot_all_metrics(results, f\"{model_name} - Basic Probe - {gallery_name.upper()} ({agg.upper()})\", plot_path)\n",
    "                        \n",
    "            gallery_results[agg] = results\n",
    "\n",
    "            df = results['threshold_results']\n",
    "            best_idx = df['rank1_accuracy'].idxmax()\n",
    "            print(f\"  Best Rank-1: {df.loc[best_idx, 'rank1_accuracy']:.4f} \"\n",
    "                f\"@ threshold {df.loc[best_idx, 'threshold']:.2f}\")\n",
    "            print(f\"  ROC-AUC: {results['roc_auc']:.4f}\")\n",
    "            print(f\"  d-prime: {results['dprime']:.3f}\")\n",
    "\n",
    "        all_results[gallery_name] = gallery_results\n",
    "    \n",
    "    return all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "e8f8cb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_impostor_evaluation(model_name: str, embeddings: Dict,\n",
    "                           results_dir: Path, plots_dir: Path):\n",
    "    \"\"\"Run impostor evaluation (ORIGINAL + ENHANCED OUTPUT)\"\"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"IMPOSTOR EVALUATION: {model_name}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    gallery = embeddings['gallery_oneshot_augmented']\n",
    "    impostor = embeddings['probe_negative']\n",
    "    \n",
    "    if gallery is None or impostor is None:\n",
    "        print(\"Missing embeddings!\")\n",
    "        return None\n",
    "    \n",
    "    thresholds = np.arange(0.2, 0.91, 0.05)\n",
    "    \n",
    "    print(\"\\nEvaluating with MEAN aggregation...\")\n",
    "    results = evaluate_impostors_comprehensive(\n",
    "        gallery, impostor, thresholds, aggregation='mean', k=3\n",
    "    )\n",
    "    \n",
    "    csv_path = results_dir / model_name / 'impostor_metrics.csv'\n",
    "    csv_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    results['threshold_results'].to_csv(csv_path, index=False)\n",
    "    \n",
    "    plot_path = plots_dir / model_name / 'impostor_plot.png'\n",
    "    plot_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    plot_impostor_metrics(results, f\"{model_name} - Impostor Rejection\", plot_path)\n",
    "\n",
    "    df = results['threshold_results']\n",
    "    best_idx = df['rejection_rate'].idxmax()\n",
    "    print(f\"  Best Rejection Rate: {df.loc[best_idx, 'rejection_rate']:.4f} \"\n",
    "          f\"@ threshold {df.loc[best_idx, 'threshold']:.2f}\")\n",
    "    print(f\"  FAR at best: {df.loc[best_idx, 'far']:.4f}\")\n",
    "    print(f\"  Total impostors: {df.loc[best_idx, 'n_impostors']}\")\n",
    "    print(f\"  Mean impostor score: {results['mean_impostor_score']:.4f}\")\n",
    "    print(f\"  Std impostor score: {results['std_impostor_score']:.4f}\")\n",
    "    print(f\"  95% CI: [{results['impostor_ci'][0]:.4f}, {results['impostor_ci'][1]:.4f}]\")\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "496cc43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_segmented_evaluation(model_name: str, embeddings: Dict,\n",
    "                             results_dir: Path, plots_dir: Path,\n",
    "                             gallery_type: str):\n",
    "    \"\"\"Run segmented evaluation (FIXED - added d-prime output)\"\"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"SEGMENTED EVALUATION: {model_name} ({gallery_type})\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    gallery_key = f'gallery_{gallery_type}_augmented'\n",
    "    gallery = embeddings[gallery_key]\n",
    "    probe = embeddings['probe_positive_segmented']\n",
    "    \n",
    "    if gallery is None or probe is None:\n",
    "        print(\"Missing embeddings!\")\n",
    "        return None\n",
    "    \n",
    "    thresholds = np.arange(0.2, 0.91, 0.05)\n",
    "    \n",
    "    print(\"\\nEvaluating with MEAN aggregation...\")\n",
    "    segment_results = evaluate_segmented_comprehensive(\n",
    "        gallery, probe, thresholds, aggregation='mean', k=3\n",
    "    )\n",
    "    \n",
    "    for segment_name, results in segment_results.items():\n",
    "        csv_path = results_dir / model_name / f'segmented_{gallery_type}_{segment_name}_metrics.csv'\n",
    "        csv_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        results['threshold_results'].to_csv(csv_path, index=False)\n",
    "\n",
    "        plot_path = plots_dir / model_name / f'segmented_{gallery_type}_{segment_name}_plot.png'\n",
    "        plot_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        plot_all_metrics(results, \n",
    "                        f\"{model_name} - {segment_name} ({gallery_type})\", \n",
    "                        plot_path)\n",
    "        \n",
    "        df = results['threshold_results']\n",
    "        best_idx = df['rank1_accuracy'].idxmax()\n",
    "        print(f\"\\n  {segment_name}:\")\n",
    "        print(f\"    Rank-1: {df.loc[best_idx, 'rank1_accuracy']:.4f} \"\n",
    "              f\"@ threshold {df.loc[best_idx, 'threshold']:.2f}\")\n",
    "        print(f\"    ROC-AUC: {results['roc_auc']:.4f}\")\n",
    "        print(f\"    d-prime: {results['dprime']:.3f}\")  # FIXED: Added d-prime output\n",
    "    \n",
    "    return segment_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "30e0b069",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_complete_evaluation_pipeline(all_embeddings: Dict, output_base_dir: Path):\n",
    "    \"\"\"\n",
    "    Complete evaluation pipeline with all analysis and comparisons\n",
    "    \n",
    "    Args:\n",
    "        all_embeddings: Dict with structure {model_name: embeddings_dict}\n",
    "        output_base_dir: Base directory for all outputs\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"COMPLETE FACE RECOGNITION EVALUATION PIPELINE\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    results_dir = output_base_dir / 'evaluation_results'\n",
    "    plots_dir = output_base_dir / 'plots'\n",
    "    comparison_dir = output_base_dir / 'comparisons'\n",
    "\n",
    "    results_dir.mkdir(parents=True, exist_ok=True)\n",
    "    plots_dir.mkdir(parents=True, exist_ok=True)\n",
    "    comparison_dir.mkdir(parents=True, exist_ok=True)\n",
    "    (comparison_dir / \"charts\").mkdir(parents=True, exist_ok=True)\n",
    "    (comparison_dir / \"reports\").mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "    all_model_results = {}\n",
    "    \n",
    "    # Run individual model evaluations\n",
    "    for model_name, embeddings in all_embeddings.items():\n",
    "        print(f\"\\n{'#'*80}\")\n",
    "        print(f\"# PROCESSING MODEL: {model_name}\")\n",
    "        print(f\"{'#'*80}\")\n",
    "        \n",
    "        model_results = {}\n",
    "        \n",
    "        # 1. Basic probe evaluation\n",
    "        model_results['basic_probe'] = run_basic_probe_evaluation(\n",
    "            model_name, embeddings, results_dir, plots_dir\n",
    "        )\n",
    "        \n",
    "        # 2. Impostor evaluation\n",
    "        model_results['impostor'] = run_impostor_evaluation(\n",
    "            model_name, embeddings, results_dir, plots_dir\n",
    "        )\n",
    "        \n",
    "        # 3. Segmented evaluation - oneshot\n",
    "        model_results['segmented_oneshot'] = run_segmented_evaluation(\n",
    "            model_name, embeddings, results_dir, plots_dir, 'oneshot'\n",
    "        )\n",
    "        \n",
    "        # 4. Segmented evaluation - fewshot\n",
    "        model_results['segmented_fewshot'] = run_segmented_evaluation(\n",
    "            model_name, embeddings, results_dir, plots_dir, 'fewshot'\n",
    "        )\n",
    "        \n",
    "        all_model_results[model_name] = model_results\n",
    "    \n",
    "    # ========================================================================\n",
    "    # COMPARATIVE ANALYSIS\n",
    "    # ========================================================================\n",
    "    \n",
    "    print(f\"\\n{'#'*80}\")\n",
    "    print(\"# COMPARATIVE ANALYSIS\")\n",
    "    print(f\"{'#'*80}\")\n",
    "    \n",
    "    all_summaries = {}\n",
    "    \n",
    "    # 1. Generate comparison summary\n",
    "    print(\"\\n1. Generating comparison summary...\")\n",
    "    all_summaries['comparison_summary'] = generate_comparison_summary(all_model_results)\n",
    "    all_summaries['comparison_summary'].to_csv(comparison_dir / 'comparison_summary.csv', index=False)\n",
    "    print(f\"   Saved: {comparison_dir / 'comparison_summary.csv'}\")\n",
    "    \n",
    "    # 2. Gallery strategy analysis\n",
    "    print(\"\\n2. Analyzing gallery strategies...\")\n",
    "    all_summaries['gallery_strategy'] = analyze_gallery_strategies(all_model_results)\n",
    "    all_summaries['gallery_strategy'].to_csv(comparison_dir / 'gallery_strategy_analysis.csv', index=False)\n",
    "    print(f\"   Saved: {comparison_dir / 'gallery_strategy_analysis.csv'}\")\n",
    "    \n",
    "    # 3. Aggregation method analysis\n",
    "    print(\"\\n3. Analyzing aggregation methods...\")\n",
    "    all_summaries['aggregation_analysis'] = summarize_aggregation_performance(all_model_results)\n",
    "    all_summaries['aggregation_analysis'].to_csv(comparison_dir / 'aggregation_analysis.csv', index=False)\n",
    "    print(f\"   Saved: {comparison_dir / 'aggregation_analysis.csv'}\")\n",
    "    \n",
    "    # 4. Threshold recommendations\n",
    "    print(\"\\n4. Generating threshold recommendations...\")\n",
    "    all_summaries['threshold_recommendations'] = recommend_operating_thresholds(all_model_results)\n",
    "    all_summaries['threshold_recommendations'].to_csv(comparison_dir / 'threshold_recommendations.csv', index=False)\n",
    "    print(f\"   Saved: {comparison_dir / 'threshold_recommendations.csv'}\")\n",
    "    \n",
    "    # 5. Segmented comparison tables\n",
    "    print(\"\\n5. Creating segmented comparison tables...\")\n",
    "    all_summaries['segmented_oneshot'] = create_segmented_comparison_table(all_model_results, 'oneshot')\n",
    "    all_summaries['segmented_oneshot'].to_csv(comparison_dir / 'segmented_oneshot_comparison.csv')\n",
    "    print(f\"   Saved: {comparison_dir / 'segmented_oneshot_comparison.csv'}\")\n",
    "    \n",
    "    all_summaries['segmented_fewshot'] = create_segmented_comparison_table(all_model_results, 'fewshot')\n",
    "    all_summaries['segmented_fewshot'].to_csv(comparison_dir / 'segmented_fewshot_comparison.csv')\n",
    "    print(f\"   Saved: {comparison_dir / 'segmented_fewshot_comparison.csv'}\")\n",
    "    \n",
    "    # 6. Failure analysis\n",
    "    print(\"\\n6. Analyzing failure cases...\")\n",
    "    all_summaries['failure_analysis'] = analyze_failure_cases(all_model_results)\n",
    "    with open(comparison_dir / 'failure_analysis.json', 'w') as f:\n",
    "        json.dump(all_summaries['failure_analysis'], f, indent=2)\n",
    "    print(f\"   Saved: {comparison_dir / 'failure_analysis.json'}\")\n",
    "    \n",
    "    # 7. Statistical comparison\n",
    "    print(\"\\n7. Performing statistical comparisons...\")\n",
    "    all_summaries['statistical_comparison'] = compare_models_statistical(all_model_results)\n",
    "    all_summaries['statistical_comparison'].to_csv(comparison_dir / 'statistical_comparison.csv', index=False)\n",
    "    print(f\"   Saved: {comparison_dir / 'statistical_comparison.csv'}\")\n",
    "    \n",
    "    # 8. Executive summary\n",
    "    print(\"\\n8. Generating executive summary...\")\n",
    "    all_summaries['executive_summary'] = generate_executive_summary(\n",
    "        all_model_results, \n",
    "        all_summaries['comparison_summary']\n",
    "    )\n",
    "    print(all_summaries['executive_summary'])\n",
    "    \n",
    "    # ========================================================================\n",
    "    # VISUALIZATIONS\n",
    "    # ========================================================================\n",
    "    \n",
    "    print(f\"\\n{'#'*80}\")\n",
    "    print(\"# GENERATING COMPARISON VISUALIZATIONS\")\n",
    "    print(f\"{'#'*80}\")\n",
    "    \n",
    "    # 1. Model comparison charts\n",
    "    print(\"\\n1. Creating model comparison charts...\")\n",
    "    plot_model_comparison_charts(\n",
    "        all_model_results,\n",
    "        all_summaries['comparison_summary'],\n",
    "        comparison_dir / 'charts'\n",
    "    )\n",
    "    \n",
    "    # 2. Segmented heatmaps\n",
    "    print(\"\\n2. Creating segmented performance heatmaps...\")\n",
    "    plot_segmented_heatmap(\n",
    "        all_summaries['segmented_oneshot'],\n",
    "        comparison_dir / 'charts' / 'segmented_oneshot_heatmap.png',\n",
    "        'Segmented Performance - Oneshot'\n",
    "    )\n",
    "    plot_segmented_heatmap(\n",
    "        all_summaries['segmented_fewshot'],\n",
    "        comparison_dir / 'charts' / 'segmented_fewshot_heatmap.png',\n",
    "        'Segmented Performance - Fewshot'\n",
    "    )\n",
    "    \n",
    "    # 3. Gallery strategy visualization\n",
    "    print(\"\\n3. Creating gallery strategy visualizations...\")\n",
    "    plot_gallery_strategy_comparison(\n",
    "        all_summaries['gallery_strategy'],\n",
    "        comparison_dir / 'charts' / 'gallery_strategy_comparison.png'\n",
    "    )\n",
    "    \n",
    "    # ========================================================================\n",
    "    # EXPORT REPORTS\n",
    "    # ========================================================================\n",
    "    \n",
    "    print(f\"\\n{'#'*80}\")\n",
    "    print(\"# EXPORTING COMPREHENSIVE REPORTS\")\n",
    "    print(f\"{'#'*80}\")\n",
    "    \n",
    "    export_comprehensive_report(\n",
    "        all_model_results,\n",
    "        all_summaries,\n",
    "        comparison_dir / 'reports'\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"EVALUATION PIPELINE COMPLETE\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"\\nAll results saved to: {output_base_dir}\")\n",
    "    print(f\"  - Individual results: {results_dir}\")\n",
    "    print(f\"  - Individual plots: {plots_dir}\")\n",
    "    print(f\"  - Comparisons: {comparison_dir}\")\n",
    "    print(f\"  - Reports: {comparison_dir / 'reports'}\")\n",
    "    \n",
    "    return all_model_results, all_summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "7ae6ccad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pkl(path: Path):\n",
    "    with open(path, \"rb\") as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "\n",
    "def load_all_embeddings(base_dir: Path):\n",
    "    \"\"\"\n",
    "    Auto-loads all embeddings following this structure:\n",
    "\n",
    "    base_dir /\n",
    "        adaface_ir_101 /\n",
    "            gallery_few-shot_augmented.pkl\n",
    "            gallery_few-shot_base.pkl\n",
    "            ...\n",
    "        arcface_ir_50 /\n",
    "            ...\n",
    "\n",
    "    Returns: dict formatted exactly for run_complete_evaluation_pipeline()\n",
    "    \"\"\"\n",
    "    mapping = {\n",
    "        \"gallery_one-shot_base.pkl\": \"gallery_oneshot_base\",\n",
    "        \"gallery_one-shot_augmented.pkl\": \"gallery_oneshot_augmented\",\n",
    "        \"gallery_few-shot_base.pkl\": \"gallery_fewshot_base\",\n",
    "        \"gallery_few-shot_augmented.pkl\": \"gallery_fewshot_augmented\",\n",
    "        \"probe_negative.pkl\": \"probe_negative\",\n",
    "        \"probe_positive_segmented.pkl\": \"probe_positive_segmented\",\n",
    "        \"probe_positive_unsegmented.pkl\": \"probe_positive_unsegmented\",\n",
    "    }\n",
    "\n",
    "    all_embeddings = {}\n",
    "\n",
    "    for model_dir in base_dir.iterdir():\n",
    "        if not model_dir.is_dir():\n",
    "            continue\n",
    "\n",
    "        model_name = model_dir.name\n",
    "        all_embeddings[model_name] = {}\n",
    "\n",
    "        for file in model_dir.iterdir():\n",
    "            if file.suffix != \".pkl\":\n",
    "                continue\n",
    "\n",
    "            key = mapping.get(file.name)\n",
    "            if key is None:\n",
    "                print(f\"Warning: Unrecognized file {file.name}, skippingâ€¦\")\n",
    "                continue\n",
    "\n",
    "            all_embeddings[model_name][key] = load_pkl(file)\n",
    "\n",
    "    return all_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "470219b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_embeddings = {}\n",
    "\n",
    "for model in models:\n",
    "    model_dir = embeddings_root / model\n",
    "    if not model_dir.exists():\n",
    "        print(f\"Warning: {model_dir} not found, skipping...\")\n",
    "        continue\n",
    "\n",
    "    all_embeddings[model] = {}\n",
    "\n",
    "    for file in model_dir.glob(\"*.pkl\"):\n",
    "        fname = file.name\n",
    "\n",
    "        # Map filename â†’ dictionary key\n",
    "        if \"one-shot_base\" in fname:\n",
    "            key = \"gallery_oneshot_base\"\n",
    "        elif \"one-shot_augmented\" in fname:\n",
    "            key = \"gallery_oneshot_augmented\"\n",
    "        elif \"few-shot_base\" in fname:\n",
    "            key = \"gallery_fewshot_base\"\n",
    "        elif \"few-shot_augmented\" in fname:\n",
    "            key = \"gallery_fewshot_augmented\"\n",
    "        else:\n",
    "            # probe_negative, probe_positive_segmented, etc.\n",
    "            key = fname.replace(\".pkl\", \"\")\n",
    "\n",
    "        with open(file, \"rb\") as f:\n",
    "            all_embeddings[model][key] = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "1befcc7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "COMPLETE FACE RECOGNITION EVALUATION PIPELINE\n",
      "================================================================================\n",
      "\n",
      "################################################################################\n",
      "# PROCESSING MODEL: adaface_ir_50\n",
      "################################################################################\n",
      "\n",
      "======================================================================\n",
      "BASIC PROBE EVALUATION: adaface_ir_50\n",
      "======================================================================\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "GALLERY: ONESHOT_BASE\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Evaluating with MAX aggregation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing probes (max): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:00<00:00, 184.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\plots\\adaface_ir_50\\basic_probe_oneshot_base_max_plot.png\n",
      "  Best Rank-1: 0.5183 @ threshold 0.20\n",
      "  ROC-AUC: 0.9150\n",
      "  d-prime: 1.360\n",
      "\n",
      "Evaluating with MEAN aggregation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing probes (mean): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:00<00:00, 111.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\plots\\adaface_ir_50\\basic_probe_oneshot_base_mean_plot.png\n",
      "  Best Rank-1: 0.5183 @ threshold 0.20\n",
      "  ROC-AUC: 0.9150\n",
      "  d-prime: 1.360\n",
      "\n",
      "Evaluating with TOPK aggregation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing probes (topk): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:00<00:00, 112.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\plots\\adaface_ir_50\\basic_probe_oneshot_base_topk_plot.png\n",
      "  Best Rank-1: 0.5183 @ threshold 0.20\n",
      "  ROC-AUC: 0.9150\n",
      "  d-prime: 1.360\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "GALLERY: ONESHOT_AUGMENTED\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Evaluating with MAX aggregation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing probes (max): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:00<00:00, 30.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\plots\\adaface_ir_50\\basic_probe_oneshot_augmented_max_plot.png\n",
      "  Best Rank-1: 0.5640 @ threshold 0.20\n",
      "  ROC-AUC: 0.8854\n",
      "  d-prime: 1.380\n",
      "\n",
      "Evaluating with MEAN aggregation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing probes (mean): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:00<00:00, 31.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\plots\\adaface_ir_50\\basic_probe_oneshot_augmented_mean_plot.png\n",
      "  Best Rank-1: 0.5457 @ threshold 0.20\n",
      "  ROC-AUC: 0.9043\n",
      "  d-prime: 1.380\n",
      "\n",
      "Evaluating with TOPK aggregation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing probes (topk): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:00<00:00, 28.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\plots\\adaface_ir_50\\basic_probe_oneshot_augmented_topk_plot.png\n",
      "  Best Rank-1: 0.5488 @ threshold 0.20\n",
      "  ROC-AUC: 0.9031\n",
      "  d-prime: 1.376\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "GALLERY: FEWSHOT_BASE\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Evaluating with MAX aggregation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing probes (max): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:00<00:00, 74.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\plots\\adaface_ir_50\\basic_probe_fewshot_base_max_plot.png\n",
      "  Best Rank-1: 0.5274 @ threshold 0.20\n",
      "  ROC-AUC: 0.9140\n",
      "  d-prime: 1.400\n",
      "\n",
      "Evaluating with MEAN aggregation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing probes (mean): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:00<00:00, 53.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\plots\\adaface_ir_50\\basic_probe_fewshot_base_mean_plot.png\n",
      "  Best Rank-1: 0.5884 @ threshold 0.20\n",
      "  ROC-AUC: 0.9225\n",
      "  d-prime: 1.440\n",
      "\n",
      "Evaluating with TOPK aggregation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing probes (topk): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:00<00:00, 52.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\plots\\adaface_ir_50\\basic_probe_fewshot_base_topk_plot.png\n",
      "  Best Rank-1: 0.5518 @ threshold 0.20\n",
      "  ROC-AUC: 0.9241\n",
      "  d-prime: 1.426\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "GALLERY: FEWSHOT_AUGMENTED\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Evaluating with MAX aggregation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing probes (max): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:02<00:00,  9.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\plots\\adaface_ir_50\\basic_probe_fewshot_augmented_max_plot.png\n",
      "  Best Rank-1: 0.5335 @ threshold 0.20\n",
      "  ROC-AUC: 0.8850\n",
      "  d-prime: 1.408\n",
      "\n",
      "Evaluating with MEAN aggregation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing probes (mean): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:02<00:00, 10.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\plots\\adaface_ir_50\\basic_probe_fewshot_augmented_mean_plot.png\n",
      "  Best Rank-1: 0.5915 @ threshold 0.20\n",
      "  ROC-AUC: 0.9184\n",
      "  d-prime: 1.454\n",
      "\n",
      "Evaluating with TOPK aggregation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing probes (topk): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:02<00:00,  9.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\plots\\adaface_ir_50\\basic_probe_fewshot_augmented_topk_plot.png\n",
      "  Best Rank-1: 0.5335 @ threshold 0.20\n",
      "  ROC-AUC: 0.9015\n",
      "  d-prime: 1.416\n",
      "\n",
      "======================================================================\n",
      "IMPOSTOR EVALUATION: adaface_ir_50\n",
      "======================================================================\n",
      "\n",
      "Evaluating with MEAN aggregation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing impostors (mean): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  3.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\plots\\adaface_ir_50\\impostor_plot.png\n",
      "  Best Rejection Rate: 1.0000 @ threshold 0.35\n",
      "  FAR at best: 0.0000\n",
      "  Total impostors: 252\n",
      "  Mean impostor score: 0.1099\n",
      "  Std impostor score: 0.0517\n",
      "  95% CI: [0.1032, 0.1161]\n",
      "\n",
      "======================================================================\n",
      "SEGMENTED EVALUATION: adaface_ir_50 (oneshot)\n",
      "======================================================================\n",
      "\n",
      "Evaluating with MEAN aggregation...\n",
      "Found 8 segments: ['baseline', 'left', 'center', 'right', 'high_pitch', 'high_yaw', 'blur', 'low_quality']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing probes (mean): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:00<00:00, 180.29it/s]\n",
      "Processing probes (mean): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:00<00:00, 83.08it/s] \n",
      "Processing probes (mean): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:00<00:00, 62.84it/s]\n",
      "Processing probes (mean): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:00<00:00, 75.75it/s]\n",
      "Processing probes (mean): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 153.80it/s]]\n",
      "Processing probes (mean): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:00<00:00, 77.46it/s]\n",
      "Processing probes (mean): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:00<00:00, 33.64it/s]\n",
      "Processing probes (mean): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:00<00:00, 59.35it/s]\n",
      "Processing segments (mean): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:04<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\plots\\adaface_ir_50\\segmented_oneshot_baseline_plot.png\n",
      "\n",
      "  baseline:\n",
      "    Rank-1: 0.9167 @ threshold 0.20\n",
      "    ROC-AUC: 0.8409\n",
      "    d-prime: 3.504\n",
      "Plot saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\plots\\adaface_ir_50\\segmented_oneshot_left_plot.png\n",
      "\n",
      "  left:\n",
      "    Rank-1: 0.5591 @ threshold 0.20\n",
      "    ROC-AUC: 0.8677\n",
      "    d-prime: 1.284\n",
      "Plot saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\plots\\adaface_ir_50\\segmented_oneshot_center_plot.png\n",
      "\n",
      "  center:\n",
      "    Rank-1: 0.5461 @ threshold 0.20\n",
      "    ROC-AUC: 0.9129\n",
      "    d-prime: 1.372\n",
      "Plot saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\plots\\adaface_ir_50\\segmented_oneshot_right_plot.png\n",
      "\n",
      "  right:\n",
      "    Rank-1: 0.5319 @ threshold 0.20\n",
      "    ROC-AUC: 0.9382\n",
      "    d-prime: 1.507\n",
      "Plot saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\plots\\adaface_ir_50\\segmented_oneshot_high_pitch_plot.png\n",
      "\n",
      "  high_pitch:\n",
      "    Rank-1: 0.2000 @ threshold 0.20\n",
      "    ROC-AUC: 0.5000\n",
      "    d-prime: 1.716\n",
      "Plot saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\plots\\adaface_ir_50\\segmented_oneshot_high_yaw_plot.png\n",
      "\n",
      "  high_yaw:\n",
      "    Rank-1: 0.3925 @ threshold 0.20\n",
      "    ROC-AUC: 0.9022\n",
      "    d-prime: 0.996\n",
      "Plot saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\plots\\adaface_ir_50\\segmented_oneshot_blur_plot.png\n",
      "\n",
      "  blur:\n",
      "    Rank-1: 0.5053 @ threshold 0.20\n",
      "    ROC-AUC: 0.8959\n",
      "    d-prime: 1.288\n",
      "Plot saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\plots\\adaface_ir_50\\segmented_oneshot_low_quality_plot.png\n",
      "\n",
      "  low_quality:\n",
      "    Rank-1: 0.4079 @ threshold 0.20\n",
      "    ROC-AUC: 0.8541\n",
      "    d-prime: 1.036\n",
      "\n",
      "======================================================================\n",
      "SEGMENTED EVALUATION: adaface_ir_50 (fewshot)\n",
      "======================================================================\n",
      "\n",
      "Evaluating with MEAN aggregation...\n",
      "Found 8 segments: ['baseline', 'left', 'center', 'right', 'high_pitch', 'high_yaw', 'blur', 'low_quality']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing probes (mean): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:00<00:00, 58.80it/s]\n",
      "Processing probes (mean): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:00<00:00, 28.87it/s]\n",
      "Processing probes (mean): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:01<00:00, 18.09it/s]\n",
      "Processing probes (mean): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:00<00:00, 21.93it/s]\n",
      "Processing probes (mean): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 45.74it/s]t]\n",
      "Processing probes (mean): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:00<00:00, 22.80it/s]\n",
      "Processing probes (mean): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:02<00:00, 10.11it/s]\n",
      "Processing probes (mean): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:01<00:00, 20.90it/s]\n",
      "Processing segments (mean): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:09<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\plots\\adaface_ir_50\\segmented_fewshot_baseline_plot.png\n",
      "\n",
      "  baseline:\n",
      "    Rank-1: 0.9167 @ threshold 0.20\n",
      "    ROC-AUC: 0.9545\n",
      "    d-prime: 3.664\n",
      "Plot saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\plots\\adaface_ir_50\\segmented_fewshot_left_plot.png\n",
      "\n",
      "  left:\n",
      "    Rank-1: 0.6129 @ threshold 0.20\n",
      "    ROC-AUC: 0.8767\n",
      "    d-prime: 1.366\n",
      "Plot saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\plots\\adaface_ir_50\\segmented_fewshot_center_plot.png\n",
      "\n",
      "  center:\n",
      "    Rank-1: 0.5674 @ threshold 0.20\n",
      "    ROC-AUC: 0.9365\n",
      "    d-prime: 1.429\n",
      "Plot saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\plots\\adaface_ir_50\\segmented_fewshot_right_plot.png\n",
      "\n",
      "  right:\n",
      "    Rank-1: 0.6064 @ threshold 0.20\n",
      "    ROC-AUC: 0.9507\n",
      "    d-prime: 1.596\n",
      "Plot saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\plots\\adaface_ir_50\\segmented_fewshot_high_pitch_plot.png\n",
      "\n",
      "  high_pitch:\n",
      "    Rank-1: 0.2000 @ threshold 0.20\n",
      "    ROC-AUC: 1.0000\n",
      "    d-prime: 1.536\n",
      "Plot saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\plots\\adaface_ir_50\\segmented_fewshot_high_yaw_plot.png\n",
      "\n",
      "  high_yaw:\n",
      "    Rank-1: 0.4486 @ threshold 0.20\n",
      "    ROC-AUC: 0.8976\n",
      "    d-prime: 1.068\n",
      "Plot saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\plots\\adaface_ir_50\\segmented_fewshot_blur_plot.png\n",
      "\n",
      "  blur:\n",
      "    Rank-1: 0.5548 @ threshold 0.20\n",
      "    ROC-AUC: 0.9096\n",
      "    d-prime: 1.371\n",
      "Plot saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\plots\\adaface_ir_50\\segmented_fewshot_low_quality_plot.png\n",
      "\n",
      "  low_quality:\n",
      "    Rank-1: 0.4737 @ threshold 0.20\n",
      "    ROC-AUC: 0.8764\n",
      "    d-prime: 1.101\n",
      "\n",
      "################################################################################\n",
      "# PROCESSING MODEL: adaface_ir_101\n",
      "################################################################################\n",
      "\n",
      "======================================================================\n",
      "BASIC PROBE EVALUATION: adaface_ir_101\n",
      "======================================================================\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "GALLERY: ONESHOT_BASE\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Evaluating with MAX aggregation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing probes (max): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:00<00:00, 204.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\plots\\adaface_ir_101\\basic_probe_oneshot_base_max_plot.png\n",
      "  Best Rank-1: 0.6189 @ threshold 0.20\n",
      "  ROC-AUC: 0.9336\n",
      "  d-prime: 1.473\n",
      "\n",
      "Evaluating with MEAN aggregation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing probes (mean): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:00<00:00, 98.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\plots\\adaface_ir_101\\basic_probe_oneshot_base_mean_plot.png\n",
      "  Best Rank-1: 0.6189 @ threshold 0.20\n",
      "  ROC-AUC: 0.9336\n",
      "  d-prime: 1.473\n",
      "\n",
      "Evaluating with TOPK aggregation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing probes (topk): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:00<00:00, 98.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\plots\\adaface_ir_101\\basic_probe_oneshot_base_topk_plot.png\n",
      "  Best Rank-1: 0.6189 @ threshold 0.20\n",
      "  ROC-AUC: 0.9336\n",
      "  d-prime: 1.473\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "GALLERY: ONESHOT_AUGMENTED\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Evaluating with MAX aggregation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing probes (max): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:00<00:00, 32.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\plots\\adaface_ir_101\\basic_probe_oneshot_augmented_max_plot.png\n",
      "  Best Rank-1: 0.6067 @ threshold 0.20\n",
      "  ROC-AUC: 0.9337\n",
      "  d-prime: 1.491\n",
      "\n",
      "Evaluating with MEAN aggregation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing probes (mean): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:00<00:00, 29.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\plots\\adaface_ir_101\\basic_probe_oneshot_augmented_mean_plot.png\n",
      "  Best Rank-1: 0.6128 @ threshold 0.20\n",
      "  ROC-AUC: 0.9408\n",
      "  d-prime: 1.489\n",
      "\n",
      "Evaluating with TOPK aggregation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing probes (topk): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:00<00:00, 27.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\plots\\adaface_ir_101\\basic_probe_oneshot_augmented_topk_plot.png\n",
      "  Best Rank-1: 0.6098 @ threshold 0.20\n",
      "  ROC-AUC: 0.9391\n",
      "  d-prime: 1.489\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "GALLERY: FEWSHOT_BASE\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Evaluating with MAX aggregation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing probes (max): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:00<00:00, 73.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\plots\\adaface_ir_101\\basic_probe_fewshot_base_max_plot.png\n",
      "  Best Rank-1: 0.5640 @ threshold 0.20\n",
      "  ROC-AUC: 0.9074\n",
      "  d-prime: 1.493\n",
      "\n",
      "Evaluating with MEAN aggregation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing probes (mean): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:00<00:00, 52.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\plots\\adaface_ir_101\\basic_probe_fewshot_base_mean_plot.png\n",
      "  Best Rank-1: 0.6341 @ threshold 0.20\n",
      "  ROC-AUC: 0.9143\n",
      "  d-prime: 1.528\n",
      "\n",
      "Evaluating with TOPK aggregation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing probes (topk): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:00<00:00, 50.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\plots\\adaface_ir_101\\basic_probe_fewshot_base_topk_plot.png\n",
      "  Best Rank-1: 0.6006 @ threshold 0.20\n",
      "  ROC-AUC: 0.9136\n",
      "  d-prime: 1.507\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "GALLERY: FEWSHOT_AUGMENTED\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Evaluating with MAX aggregation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing probes (max): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:02<00:00,  9.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\plots\\adaface_ir_101\\basic_probe_fewshot_augmented_max_plot.png\n",
      "  Best Rank-1: 0.5610 @ threshold 0.20\n",
      "  ROC-AUC: 0.9063\n",
      "  d-prime: 1.494\n",
      "\n",
      "Evaluating with MEAN aggregation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing probes (mean): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:02<00:00, 10.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\plots\\adaface_ir_101\\basic_probe_fewshot_augmented_mean_plot.png\n",
      "  Best Rank-1: 0.6463 @ threshold 0.20\n",
      "  ROC-AUC: 0.9122\n",
      "  d-prime: 1.542\n",
      "\n",
      "Evaluating with TOPK aggregation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing probes (topk): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:02<00:00,  9.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\plots\\adaface_ir_101\\basic_probe_fewshot_augmented_topk_plot.png\n",
      "  Best Rank-1: 0.5671 @ threshold 0.20\n",
      "  ROC-AUC: 0.8953\n",
      "  d-prime: 1.502\n",
      "\n",
      "======================================================================\n",
      "IMPOSTOR EVALUATION: adaface_ir_101\n",
      "======================================================================\n",
      "\n",
      "Evaluating with MEAN aggregation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing impostors (mean): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  3.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\plots\\adaface_ir_101\\impostor_plot.png\n",
      "  Best Rejection Rate: 1.0000 @ threshold 0.35\n",
      "  FAR at best: 0.0000\n",
      "  Total impostors: 252\n",
      "  Mean impostor score: 0.1001\n",
      "  Std impostor score: 0.0557\n",
      "  95% CI: [0.0939, 0.1076]\n",
      "\n",
      "======================================================================\n",
      "SEGMENTED EVALUATION: adaface_ir_101 (oneshot)\n",
      "======================================================================\n",
      "\n",
      "Evaluating with MEAN aggregation...\n",
      "Found 8 segments: ['baseline', 'left', 'center', 'right', 'high_pitch', 'high_yaw', 'blur', 'low_quality']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing probes (mean): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:00<00:00, 206.65it/s]\n",
      "Processing probes (mean): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:00<00:00, 91.67it/s] \n",
      "Processing probes (mean): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:00<00:00, 62.58it/s]\n",
      "Processing probes (mean): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:00<00:00, 76.52it/s]\n",
      "Processing probes (mean): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 166.72it/s]]\n",
      "Processing probes (mean): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:00<00:00, 78.57it/s]\n",
      "Processing probes (mean): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:00<00:00, 33.07it/s]\n",
      "Processing probes (mean): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:00<00:00, 60.99it/s]\n",
      "Processing segments (mean): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:04<00:00,  1.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\plots\\adaface_ir_101\\segmented_oneshot_baseline_plot.png\n",
      "\n",
      "  baseline:\n",
      "    Rank-1: 0.9583 @ threshold 0.20\n",
      "    ROC-AUC: 1.0000\n",
      "    d-prime: 3.516\n",
      "Plot saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\plots\\adaface_ir_101\\segmented_oneshot_left_plot.png\n",
      "\n",
      "  left:\n",
      "    Rank-1: 0.6129 @ threshold 0.20\n",
      "    ROC-AUC: 0.9488\n",
      "    d-prime: 1.412\n",
      "Plot saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\plots\\adaface_ir_101\\segmented_oneshot_center_plot.png\n",
      "\n",
      "  center:\n",
      "    Rank-1: 0.6028 @ threshold 0.20\n",
      "    ROC-AUC: 0.9244\n",
      "    d-prime: 1.460\n",
      "Plot saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\plots\\adaface_ir_101\\segmented_oneshot_right_plot.png\n",
      "\n",
      "  right:\n",
      "    Rank-1: 0.6277 @ threshold 0.20\n",
      "    ROC-AUC: 0.9554\n",
      "    d-prime: 1.622\n",
      "Plot saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\plots\\adaface_ir_101\\segmented_oneshot_high_pitch_plot.png\n",
      "\n",
      "  high_pitch:\n",
      "    Rank-1: 0.4000 @ threshold 0.20\n",
      "    ROC-AUC: 0.8333\n",
      "    d-prime: 1.838\n",
      "Plot saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\plots\\adaface_ir_101\\segmented_oneshot_high_yaw_plot.png\n",
      "\n",
      "  high_yaw:\n",
      "    Rank-1: 0.4393 @ threshold 0.20\n",
      "    ROC-AUC: 0.9514\n",
      "    d-prime: 1.100\n",
      "Plot saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\plots\\adaface_ir_101\\segmented_oneshot_blur_plot.png\n",
      "\n",
      "  blur:\n",
      "    Rank-1: 0.5724 @ threshold 0.20\n",
      "    ROC-AUC: 0.9386\n",
      "    d-prime: 1.409\n",
      "Plot saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\plots\\adaface_ir_101\\segmented_oneshot_low_quality_plot.png\n",
      "\n",
      "  low_quality:\n",
      "    Rank-1: 0.4276 @ threshold 0.20\n",
      "    ROC-AUC: 0.9134\n",
      "    d-prime: 1.108\n",
      "\n",
      "======================================================================\n",
      "SEGMENTED EVALUATION: adaface_ir_101 (fewshot)\n",
      "======================================================================\n",
      "\n",
      "Evaluating with MEAN aggregation...\n",
      "Found 8 segments: ['baseline', 'left', 'center', 'right', 'high_pitch', 'high_yaw', 'blur', 'low_quality']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing probes (mean): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:00<00:00, 66.64it/s]\n",
      "c:\\Users\\kevin\\.conda\\envs\\adaface\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:1192: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless\n",
      "  warnings.warn(\n",
      "Processing probes (mean): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:00<00:00, 30.12it/s]\n",
      "Processing probes (mean): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:01<00:00, 20.47it/s]\n",
      "Processing probes (mean): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:00<00:00, 25.84it/s]\n",
      "Processing probes (mean): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 54.05it/s]s]\n",
      "Processing probes (mean): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:00<00:00, 27.40it/s]\n",
      "Processing probes (mean): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:02<00:00, 10.97it/s]\n",
      "Processing probes (mean): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:01<00:00, 19.46it/s]\n",
      "Processing segments (mean): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:08<00:00,  1.07s/it]\n",
      "C:\\Users\\kevin\\AppData\\Local\\Temp\\ipykernel_14580\\2538557133.py:68: UserWarning: Data has no positive values, and therefore cannot be log-scaled.\n",
      "  ax7.set_xscale('log')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\plots\\adaface_ir_101\\segmented_fewshot_baseline_plot.png\n",
      "\n",
      "  baseline:\n",
      "    Rank-1: 1.0000 @ threshold 0.20\n",
      "    ROC-AUC: nan\n",
      "    d-prime: 3.954\n",
      "Plot saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\plots\\adaface_ir_101\\segmented_fewshot_left_plot.png\n",
      "\n",
      "  left:\n",
      "    Rank-1: 0.6344 @ threshold 0.20\n",
      "    ROC-AUC: 0.9327\n",
      "    d-prime: 1.454\n",
      "Plot saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\plots\\adaface_ir_101\\segmented_fewshot_center_plot.png\n",
      "\n",
      "  center:\n",
      "    Rank-1: 0.6312 @ threshold 0.20\n",
      "    ROC-AUC: 0.8917\n",
      "    d-prime: 1.507\n",
      "Plot saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\plots\\adaface_ir_101\\segmented_fewshot_right_plot.png\n",
      "\n",
      "  right:\n",
      "    Rank-1: 0.6809 @ threshold 0.20\n",
      "    ROC-AUC: 0.9182\n",
      "    d-prime: 1.698\n",
      "Plot saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\plots\\adaface_ir_101\\segmented_fewshot_high_pitch_plot.png\n",
      "\n",
      "  high_pitch:\n",
      "    Rank-1: 0.6000 @ threshold 0.20\n",
      "    ROC-AUC: 0.6667\n",
      "    d-prime: 1.975\n",
      "Plot saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\plots\\adaface_ir_101\\segmented_fewshot_high_yaw_plot.png\n",
      "\n",
      "  high_yaw:\n",
      "    Rank-1: 0.4860 @ threshold 0.20\n",
      "    ROC-AUC: 0.8913\n",
      "    d-prime: 1.139\n",
      "Plot saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\plots\\adaface_ir_101\\segmented_fewshot_blur_plot.png\n",
      "\n",
      "  blur:\n",
      "    Rank-1: 0.6007 @ threshold 0.20\n",
      "    ROC-AUC: 0.9065\n",
      "    d-prime: 1.456\n",
      "Plot saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\plots\\adaface_ir_101\\segmented_fewshot_low_quality_plot.png\n",
      "\n",
      "  low_quality:\n",
      "    Rank-1: 0.5000 @ threshold 0.20\n",
      "    ROC-AUC: 0.8499\n",
      "    d-prime: 1.153\n",
      "\n",
      "################################################################################\n",
      "# PROCESSING MODEL: arcface_ir_50\n",
      "################################################################################\n",
      "\n",
      "======================================================================\n",
      "BASIC PROBE EVALUATION: arcface_ir_50\n",
      "======================================================================\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "GALLERY: ONESHOT_BASE\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Evaluating with MAX aggregation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing probes (max): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:00<00:00, 256.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\plots\\arcface_ir_50\\basic_probe_oneshot_base_max_plot.png\n",
      "  Best Rank-1: 0.4970 @ threshold 0.20\n",
      "  ROC-AUC: 0.8733\n",
      "  d-prime: 1.246\n",
      "\n",
      "Evaluating with MEAN aggregation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing probes (mean): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:00<00:00, 122.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\plots\\arcface_ir_50\\basic_probe_oneshot_base_mean_plot.png\n",
      "  Best Rank-1: 0.4970 @ threshold 0.20\n",
      "  ROC-AUC: 0.8733\n",
      "  d-prime: 1.246\n",
      "\n",
      "Evaluating with TOPK aggregation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing probes (topk): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:00<00:00, 117.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\plots\\arcface_ir_50\\basic_probe_oneshot_base_topk_plot.png\n",
      "  Best Rank-1: 0.4970 @ threshold 0.20\n",
      "  ROC-AUC: 0.8733\n",
      "  d-prime: 1.246\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "GALLERY: ONESHOT_AUGMENTED\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Evaluating with MAX aggregation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing probes (max): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:00<00:00, 37.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\plots\\arcface_ir_50\\basic_probe_oneshot_augmented_max_plot.png\n",
      "  Best Rank-1: 0.4817 @ threshold 0.20\n",
      "  ROC-AUC: 0.8941\n",
      "  d-prime: 1.226\n",
      "\n",
      "Evaluating with MEAN aggregation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing probes (mean): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:00<00:00, 32.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\plots\\arcface_ir_50\\basic_probe_oneshot_augmented_mean_plot.png\n",
      "  Best Rank-1: 0.4878 @ threshold 0.20\n",
      "  ROC-AUC: 0.8925\n",
      "  d-prime: 1.248\n",
      "\n",
      "Evaluating with TOPK aggregation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing probes (topk): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:00<00:00, 31.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\plots\\arcface_ir_50\\basic_probe_oneshot_augmented_topk_plot.png\n",
      "  Best Rank-1: 0.4848 @ threshold 0.20\n",
      "  ROC-AUC: 0.8860\n",
      "  d-prime: 1.237\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "GALLERY: FEWSHOT_BASE\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Evaluating with MAX aggregation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing probes (max): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:00<00:00, 81.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\plots\\arcface_ir_50\\basic_probe_fewshot_base_max_plot.png\n",
      "  Best Rank-1: 0.4939 @ threshold 0.20\n",
      "  ROC-AUC: 0.9157\n",
      "  d-prime: 1.222\n",
      "\n",
      "Evaluating with MEAN aggregation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing probes (mean): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:00<00:00, 56.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\plots\\arcface_ir_50\\basic_probe_fewshot_base_mean_plot.png\n",
      "  Best Rank-1: 0.5335 @ threshold 0.20\n",
      "  ROC-AUC: 0.8892\n",
      "  d-prime: 1.266\n",
      "\n",
      "Evaluating with TOPK aggregation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing probes (topk): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:00<00:00, 57.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\plots\\arcface_ir_50\\basic_probe_fewshot_base_topk_plot.png\n",
      "  Best Rank-1: 0.5244 @ threshold 0.20\n",
      "  ROC-AUC: 0.8830\n",
      "  d-prime: 1.246\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "GALLERY: FEWSHOT_AUGMENTED\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Evaluating with MAX aggregation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing probes (max): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:02<00:00, 10.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\plots\\arcface_ir_50\\basic_probe_fewshot_augmented_max_plot.png\n",
      "  Best Rank-1: 0.4878 @ threshold 0.20\n",
      "  ROC-AUC: 0.8882\n",
      "  d-prime: 1.216\n",
      "\n",
      "Evaluating with MEAN aggregation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing probes (mean): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:02<00:00, 10.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\plots\\arcface_ir_50\\basic_probe_fewshot_augmented_mean_plot.png\n",
      "  Best Rank-1: 0.5335 @ threshold 0.20\n",
      "  ROC-AUC: 0.8948\n",
      "  d-prime: 1.279\n",
      "\n",
      "Evaluating with TOPK aggregation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing probes (topk): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:02<00:00, 10.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\plots\\arcface_ir_50\\basic_probe_fewshot_augmented_topk_plot.png\n",
      "  Best Rank-1: 0.5000 @ threshold 0.20\n",
      "  ROC-AUC: 0.8925\n",
      "  d-prime: 1.228\n",
      "\n",
      "======================================================================\n",
      "IMPOSTOR EVALUATION: arcface_ir_50\n",
      "======================================================================\n",
      "\n",
      "Evaluating with MEAN aggregation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing impostors (mean): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  3.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\plots\\arcface_ir_50\\impostor_plot.png\n",
      "  Best Rejection Rate: 1.0000 @ threshold 0.40\n",
      "  FAR at best: 0.0000\n",
      "  Total impostors: 252\n",
      "  Mean impostor score: 0.1455\n",
      "  Std impostor score: 0.0546\n",
      "  95% CI: [0.1387, 0.1521]\n",
      "\n",
      "======================================================================\n",
      "SEGMENTED EVALUATION: arcface_ir_50 (oneshot)\n",
      "======================================================================\n",
      "\n",
      "Evaluating with MEAN aggregation...\n",
      "Found 8 segments: ['baseline', 'left', 'center', 'right', 'high_pitch', 'high_yaw', 'blur', 'low_quality']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing probes (mean): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:00<00:00, 209.47it/s]\n",
      "Processing probes (mean): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:00<00:00, 99.86it/s] \n",
      "Processing probes (mean): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:00<00:00, 69.69it/s]\n",
      "Processing probes (mean): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:00<00:00, 86.85it/s]\n",
      "Processing probes (mean): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 173.40it/s]]\n",
      "Processing probes (mean): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:00<00:00, 89.16it/s]\n",
      "Processing probes (mean): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:00<00:00, 37.23it/s]\n",
      "Processing probes (mean): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:00<00:00, 65.00it/s]\n",
      "Processing segments (mean): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\plots\\arcface_ir_50\\segmented_oneshot_baseline_plot.png\n",
      "\n",
      "  baseline:\n",
      "    Rank-1: 0.7917 @ threshold 0.20\n",
      "    ROC-AUC: 0.8000\n",
      "    d-prime: 2.280\n",
      "Plot saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\plots\\arcface_ir_50\\segmented_oneshot_left_plot.png\n",
      "\n",
      "  left:\n",
      "    Rank-1: 0.4839 @ threshold 0.20\n",
      "    ROC-AUC: 0.8829\n",
      "    d-prime: 1.163\n",
      "Plot saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\plots\\arcface_ir_50\\segmented_oneshot_center_plot.png\n",
      "\n",
      "  center:\n",
      "    Rank-1: 0.4610 @ threshold 0.20\n",
      "    ROC-AUC: 0.9221\n",
      "    d-prime: 1.243\n",
      "Plot saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\plots\\arcface_ir_50\\segmented_oneshot_right_plot.png\n",
      "\n",
      "  right:\n",
      "    Rank-1: 0.5319 @ threshold 0.20\n",
      "    ROC-AUC: 0.8514\n",
      "    d-prime: 1.358\n",
      "Plot saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\plots\\arcface_ir_50\\segmented_oneshot_high_pitch_plot.png\n",
      "\n",
      "  high_pitch:\n",
      "    Rank-1: 0.2000 @ threshold 0.20\n",
      "    ROC-AUC: 0.7500\n",
      "    d-prime: 2.039\n",
      "Plot saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\plots\\arcface_ir_50\\segmented_oneshot_high_yaw_plot.png\n",
      "\n",
      "  high_yaw:\n",
      "    Rank-1: 0.3364 @ threshold 0.20\n",
      "    ROC-AUC: 0.8439\n",
      "    d-prime: 0.995\n",
      "Plot saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\plots\\arcface_ir_50\\segmented_oneshot_blur_plot.png\n",
      "\n",
      "  blur:\n",
      "    Rank-1: 0.4558 @ threshold 0.20\n",
      "    ROC-AUC: 0.8914\n",
      "    d-prime: 1.190\n",
      "Plot saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\plots\\arcface_ir_50\\segmented_oneshot_low_quality_plot.png\n",
      "\n",
      "  low_quality:\n",
      "    Rank-1: 0.3224 @ threshold 0.20\n",
      "    ROC-AUC: 0.8890\n",
      "    d-prime: 0.909\n",
      "\n",
      "======================================================================\n",
      "SEGMENTED EVALUATION: arcface_ir_50 (fewshot)\n",
      "======================================================================\n",
      "\n",
      "Evaluating with MEAN aggregation...\n",
      "Found 8 segments: ['baseline', 'left', 'center', 'right', 'high_pitch', 'high_yaw', 'blur', 'low_quality']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing probes (mean): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:00<00:00, 63.48it/s]\n",
      "Processing probes (mean): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:00<00:00, 32.15it/s]\n",
      "Processing probes (mean): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:00<00:00, 22.99it/s]\n",
      "Processing probes (mean): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:00<00:00, 28.53it/s]\n",
      "Processing probes (mean): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 60.50it/s]s]\n",
      "Processing probes (mean): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:00<00:00, 27.45it/s]\n",
      "Processing probes (mean): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:02<00:00, 11.49it/s]\n",
      "Processing probes (mean): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:01<00:00, 21.38it/s]\n",
      "Processing segments (mean): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:08<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\plots\\arcface_ir_50\\segmented_fewshot_baseline_plot.png\n",
      "\n",
      "  baseline:\n",
      "    Rank-1: 0.8750 @ threshold 0.20\n",
      "    ROC-AUC: 0.9206\n",
      "    d-prime: 2.538\n",
      "Plot saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\plots\\arcface_ir_50\\segmented_fewshot_left_plot.png\n",
      "\n",
      "  left:\n",
      "    Rank-1: 0.5161 @ threshold 0.20\n",
      "    ROC-AUC: 0.8940\n",
      "    d-prime: 1.201\n",
      "Plot saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\plots\\arcface_ir_50\\segmented_fewshot_center_plot.png\n",
      "\n",
      "  center:\n",
      "    Rank-1: 0.4894 @ threshold 0.20\n",
      "    ROC-AUC: 0.9157\n",
      "    d-prime: 1.249\n",
      "Plot saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\plots\\arcface_ir_50\\segmented_fewshot_right_plot.png\n",
      "\n",
      "  right:\n",
      "    Rank-1: 0.6170 @ threshold 0.20\n",
      "    ROC-AUC: 0.8688\n",
      "    d-prime: 1.414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kevin\\AppData\\Local\\Temp\\ipykernel_14580\\2538557133.py:68: UserWarning: Data has no positive values, and therefore cannot be log-scaled.\n",
      "  ax7.set_xscale('log')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\plots\\arcface_ir_50\\segmented_fewshot_high_pitch_plot.png\n",
      "\n",
      "  high_pitch:\n",
      "    Rank-1: 0.4000 @ threshold 0.20\n",
      "    ROC-AUC: 0.3333\n",
      "    d-prime: 1.937\n",
      "Plot saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\plots\\arcface_ir_50\\segmented_fewshot_high_yaw_plot.png\n",
      "\n",
      "  high_yaw:\n",
      "    Rank-1: 0.3645 @ threshold 0.20\n",
      "    ROC-AUC: 0.8035\n",
      "    d-prime: 0.999\n",
      "Plot saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\plots\\arcface_ir_50\\segmented_fewshot_blur_plot.png\n",
      "\n",
      "  blur:\n",
      "    Rank-1: 0.4982 @ threshold 0.20\n",
      "    ROC-AUC: 0.8839\n",
      "    d-prime: 1.214\n",
      "Plot saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\plots\\arcface_ir_50\\segmented_fewshot_low_quality_plot.png\n",
      "\n",
      "  low_quality:\n",
      "    Rank-1: 0.3487 @ threshold 0.20\n",
      "    ROC-AUC: 0.8696\n",
      "    d-prime: 0.919\n",
      "\n",
      "################################################################################\n",
      "# PROCESSING MODEL: arcface_ir_101\n",
      "################################################################################\n",
      "\n",
      "======================================================================\n",
      "BASIC PROBE EVALUATION: arcface_ir_101\n",
      "======================================================================\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "GALLERY: ONESHOT_BASE\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Evaluating with MAX aggregation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing probes (max): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:00<00:00, 251.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\plots\\arcface_ir_101\\basic_probe_oneshot_base_max_plot.png\n",
      "  Best Rank-1: 0.5518 @ threshold 0.20\n",
      "  ROC-AUC: 0.9005\n",
      "  d-prime: 1.367\n",
      "\n",
      "Evaluating with MEAN aggregation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing probes (mean): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:00<00:00, 121.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\plots\\arcface_ir_101\\basic_probe_oneshot_base_mean_plot.png\n",
      "  Best Rank-1: 0.5518 @ threshold 0.20\n",
      "  ROC-AUC: 0.9005\n",
      "  d-prime: 1.367\n",
      "\n",
      "Evaluating with TOPK aggregation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing probes (topk): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:00<00:00, 114.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\plots\\arcface_ir_101\\basic_probe_oneshot_base_topk_plot.png\n",
      "  Best Rank-1: 0.5518 @ threshold 0.20\n",
      "  ROC-AUC: 0.9005\n",
      "  d-prime: 1.367\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "GALLERY: ONESHOT_AUGMENTED\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Evaluating with MAX aggregation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing probes (max): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:00<00:00, 38.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\plots\\arcface_ir_101\\basic_probe_oneshot_augmented_max_plot.png\n",
      "  Best Rank-1: 0.5579 @ threshold 0.20\n",
      "  ROC-AUC: 0.8894\n",
      "  d-prime: 1.363\n",
      "\n",
      "Evaluating with MEAN aggregation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing probes (mean): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:00<00:00, 31.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\plots\\arcface_ir_101\\basic_probe_oneshot_augmented_mean_plot.png\n",
      "  Best Rank-1: 0.5579 @ threshold 0.20\n",
      "  ROC-AUC: 0.8893\n",
      "  d-prime: 1.370\n",
      "\n",
      "Evaluating with TOPK aggregation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing probes (topk): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:00<00:00, 29.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\plots\\arcface_ir_101\\basic_probe_oneshot_augmented_topk_plot.png\n",
      "  Best Rank-1: 0.5579 @ threshold 0.20\n",
      "  ROC-AUC: 0.8911\n",
      "  d-prime: 1.367\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "GALLERY: FEWSHOT_BASE\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Evaluating with MAX aggregation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing probes (max): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:00<00:00, 75.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\plots\\arcface_ir_101\\basic_probe_fewshot_base_max_plot.png\n",
      "  Best Rank-1: 0.5366 @ threshold 0.20\n",
      "  ROC-AUC: 0.9163\n",
      "  d-prime: 1.358\n",
      "\n",
      "Evaluating with MEAN aggregation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing probes (mean): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:00<00:00, 58.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\plots\\arcface_ir_101\\basic_probe_fewshot_base_mean_plot.png\n",
      "  Best Rank-1: 0.5945 @ threshold 0.20\n",
      "  ROC-AUC: 0.9277\n",
      "  d-prime: 1.407\n",
      "\n",
      "Evaluating with TOPK aggregation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing probes (topk): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:00<00:00, 50.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\plots\\arcface_ir_101\\basic_probe_fewshot_base_topk_plot.png\n",
      "  Best Rank-1: 0.5701 @ threshold 0.20\n",
      "  ROC-AUC: 0.9218\n",
      "  d-prime: 1.385\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "GALLERY: FEWSHOT_AUGMENTED\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Evaluating with MAX aggregation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing probes (max): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:02<00:00, 10.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\plots\\arcface_ir_101\\basic_probe_fewshot_augmented_max_plot.png\n",
      "  Best Rank-1: 0.5366 @ threshold 0.20\n",
      "  ROC-AUC: 0.8137\n",
      "  d-prime: 1.330\n",
      "\n",
      "Evaluating with MEAN aggregation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing probes (mean): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:02<00:00,  9.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\plots\\arcface_ir_101\\basic_probe_fewshot_augmented_mean_plot.png\n",
      "  Best Rank-1: 0.5854 @ threshold 0.20\n",
      "  ROC-AUC: 0.9409\n",
      "  d-prime: 1.413\n",
      "\n",
      "Evaluating with TOPK aggregation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing probes (topk): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:02<00:00, 10.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\plots\\arcface_ir_101\\basic_probe_fewshot_augmented_topk_plot.png\n",
      "  Best Rank-1: 0.5427 @ threshold 0.20\n",
      "  ROC-AUC: 0.9005\n",
      "  d-prime: 1.352\n",
      "\n",
      "======================================================================\n",
      "IMPOSTOR EVALUATION: arcface_ir_101\n",
      "======================================================================\n",
      "\n",
      "Evaluating with MEAN aggregation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing impostors (mean): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  3.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\plots\\arcface_ir_101\\impostor_plot.png\n",
      "  Best Rejection Rate: 1.0000 @ threshold 0.40\n",
      "  FAR at best: 0.0000\n",
      "  Total impostors: 252\n",
      "  Mean impostor score: 0.1377\n",
      "  Std impostor score: 0.0537\n",
      "  95% CI: [0.1311, 0.1440]\n",
      "\n",
      "======================================================================\n",
      "SEGMENTED EVALUATION: arcface_ir_101 (oneshot)\n",
      "======================================================================\n",
      "\n",
      "Evaluating with MEAN aggregation...\n",
      "Found 8 segments: ['baseline', 'left', 'center', 'right', 'high_pitch', 'high_yaw', 'blur', 'low_quality']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing probes (mean): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:00<00:00, 187.84it/s]\n",
      "Processing probes (mean): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:00<00:00, 93.31it/s] \n",
      "Processing probes (mean): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:00<00:00, 59.60it/s]\n",
      "Processing probes (mean): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:00<00:00, 82.91it/s]\n",
      "Processing probes (mean): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 163.69it/s]]\n",
      "Processing probes (mean): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:00<00:00, 70.73it/s]\n",
      "Processing probes (mean): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:00<00:00, 32.57it/s]\n",
      "Processing probes (mean): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:00<00:00, 62.18it/s]\n",
      "Processing segments (mean): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:04<00:00,  1.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\plots\\arcface_ir_101\\segmented_oneshot_baseline_plot.png\n",
      "\n",
      "  baseline:\n",
      "    Rank-1: 0.7917 @ threshold 0.20\n",
      "    ROC-AUC: 0.8632\n",
      "    d-prime: 3.081\n",
      "Plot saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\plots\\arcface_ir_101\\segmented_oneshot_left_plot.png\n",
      "\n",
      "  left:\n",
      "    Rank-1: 0.5484 @ threshold 0.20\n",
      "    ROC-AUC: 0.8679\n",
      "    d-prime: 1.304\n",
      "Plot saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\plots\\arcface_ir_101\\segmented_oneshot_center_plot.png\n",
      "\n",
      "  center:\n",
      "    Rank-1: 0.5603 @ threshold 0.20\n",
      "    ROC-AUC: 0.8722\n",
      "    d-prime: 1.335\n",
      "Plot saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\plots\\arcface_ir_101\\segmented_oneshot_right_plot.png\n",
      "\n",
      "  right:\n",
      "    Rank-1: 0.5638 @ threshold 0.20\n",
      "    ROC-AUC: 0.9314\n",
      "    d-prime: 1.503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kevin\\AppData\\Local\\Temp\\ipykernel_14580\\2538557133.py:68: UserWarning: Data has no positive values, and therefore cannot be log-scaled.\n",
      "  ax7.set_xscale('log')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\plots\\arcface_ir_101\\segmented_oneshot_high_pitch_plot.png\n",
      "\n",
      "  high_pitch:\n",
      "    Rank-1: 0.4000 @ threshold 0.20\n",
      "    ROC-AUC: 1.0000\n",
      "    d-prime: 1.129\n",
      "Plot saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\plots\\arcface_ir_101\\segmented_oneshot_high_yaw_plot.png\n",
      "\n",
      "  high_yaw:\n",
      "    Rank-1: 0.4486 @ threshold 0.20\n",
      "    ROC-AUC: 0.8566\n",
      "    d-prime: 1.095\n",
      "Plot saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\plots\\arcface_ir_101\\segmented_oneshot_blur_plot.png\n",
      "\n",
      "  blur:\n",
      "    Rank-1: 0.5194 @ threshold 0.20\n",
      "    ROC-AUC: 0.8936\n",
      "    d-prime: 1.282\n",
      "Plot saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\plots\\arcface_ir_101\\segmented_oneshot_low_quality_plot.png\n",
      "\n",
      "  low_quality:\n",
      "    Rank-1: 0.4211 @ threshold 0.20\n",
      "    ROC-AUC: 0.8881\n",
      "    d-prime: 1.031\n",
      "\n",
      "======================================================================\n",
      "SEGMENTED EVALUATION: arcface_ir_101 (fewshot)\n",
      "======================================================================\n",
      "\n",
      "Evaluating with MEAN aggregation...\n",
      "Found 8 segments: ['baseline', 'left', 'center', 'right', 'high_pitch', 'high_yaw', 'blur', 'low_quality']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing probes (mean): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:00<00:00, 67.42it/s]\n",
      "Processing probes (mean): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:00<00:00, 33.16it/s]\n",
      "Processing probes (mean): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:00<00:00, 22.83it/s]\n",
      "Processing probes (mean): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:00<00:00, 27.88it/s]\n",
      "Processing probes (mean): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 60.61it/s]s]\n",
      "Processing probes (mean): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:00<00:00, 29.08it/s]\n",
      "Processing probes (mean): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:01<00:00, 12.14it/s]\n",
      "Processing probes (mean): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:01<00:00, 19.95it/s]\n",
      "Processing segments (mean): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:07<00:00,  1.01it/s]\n",
      "C:\\Users\\kevin\\AppData\\Local\\Temp\\ipykernel_14580\\2538557133.py:68: UserWarning: Data has no positive values, and therefore cannot be log-scaled.\n",
      "  ax7.set_xscale('log')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\plots\\arcface_ir_101\\segmented_fewshot_baseline_plot.png\n",
      "\n",
      "  baseline:\n",
      "    Rank-1: 0.9583 @ threshold 0.20\n",
      "    ROC-AUC: 1.0000\n",
      "    d-prime: 3.172\n",
      "Plot saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\plots\\arcface_ir_101\\segmented_fewshot_left_plot.png\n",
      "\n",
      "  left:\n",
      "    Rank-1: 0.5484 @ threshold 0.20\n",
      "    ROC-AUC: 0.9290\n",
      "    d-prime: 1.343\n",
      "Plot saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\plots\\arcface_ir_101\\segmented_fewshot_center_plot.png\n",
      "\n",
      "  center:\n",
      "    Rank-1: 0.5957 @ threshold 0.20\n",
      "    ROC-AUC: 0.9373\n",
      "    d-prime: 1.378\n",
      "Plot saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\plots\\arcface_ir_101\\segmented_fewshot_right_plot.png\n",
      "\n",
      "  right:\n",
      "    Rank-1: 0.6064 @ threshold 0.20\n",
      "    ROC-AUC: 0.9587\n",
      "    d-prime: 1.544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kevin\\AppData\\Local\\Temp\\ipykernel_14580\\2538557133.py:68: UserWarning: Data has no positive values, and therefore cannot be log-scaled.\n",
      "  ax7.set_xscale('log')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\plots\\arcface_ir_101\\segmented_fewshot_high_pitch_plot.png\n",
      "\n",
      "  high_pitch:\n",
      "    Rank-1: 0.6000 @ threshold 0.20\n",
      "    ROC-AUC: 1.0000\n",
      "    d-prime: 1.108\n",
      "Plot saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\plots\\arcface_ir_101\\segmented_fewshot_high_yaw_plot.png\n",
      "\n",
      "  high_yaw:\n",
      "    Rank-1: 0.4299 @ threshold 0.20\n",
      "    ROC-AUC: 0.9191\n",
      "    d-prime: 1.113\n",
      "Plot saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\plots\\arcface_ir_101\\segmented_fewshot_blur_plot.png\n",
      "\n",
      "  blur:\n",
      "    Rank-1: 0.5336 @ threshold 0.20\n",
      "    ROC-AUC: 0.9427\n",
      "    d-prime: 1.327\n",
      "Plot saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\plots\\arcface_ir_101\\segmented_fewshot_low_quality_plot.png\n",
      "\n",
      "  low_quality:\n",
      "    Rank-1: 0.4276 @ threshold 0.20\n",
      "    ROC-AUC: 0.9294\n",
      "    d-prime: 1.065\n",
      "\n",
      "################################################################################\n",
      "# COMPARATIVE ANALYSIS\n",
      "################################################################################\n",
      "\n",
      "1. Generating comparison summary...\n",
      "   Saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\comparisons\\comparison_summary.csv\n",
      "\n",
      "2. Analyzing gallery strategies...\n",
      "   Saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\comparisons\\gallery_strategy_analysis.csv\n",
      "\n",
      "3. Analyzing aggregation methods...\n",
      "   Saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\comparisons\\aggregation_analysis.csv\n",
      "\n",
      "4. Generating threshold recommendations...\n",
      "   Saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\comparisons\\threshold_recommendations.csv\n",
      "\n",
      "5. Creating segmented comparison tables...\n",
      "   Saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\comparisons\\segmented_oneshot_comparison.csv\n",
      "   Saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\comparisons\\segmented_fewshot_comparison.csv\n",
      "\n",
      "6. Analyzing failure cases...\n",
      "   Saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\comparisons\\failure_analysis.json\n",
      "\n",
      "7. Performing statistical comparisons...\n",
      "   Saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\comparisons\\statistical_comparison.csv\n",
      "\n",
      "8. Generating executive summary...\n",
      "\n",
      "================================================================================\n",
      "EXECUTIVE SUMMARY - Face Recognition Evaluation\n",
      "Generated: 2025-12-05 16:31:47\n",
      "================================================================================\n",
      "\n",
      "KEY FINDINGS:\n",
      "\n",
      "1. OVERALL BEST PERFORMANCE\n",
      "   Model: adaface_ir_101\n",
      "   Configuration: fewshot_augmented + mean\n",
      "   Rank-1 Accuracy: 64.63%\n",
      "   ROC-AUC: 0.9122\n",
      "   d-prime: 1.542\n",
      "\n",
      "2. BEST CONFIGURATION PER GALLERY TYPE\n",
      "\n",
      "   FEWSHOT_AUGMENTED:\n",
      "   - Model: adaface_ir_101 (mean)\n",
      "   - Rank-1: 64.63%\n",
      "   - ROC-AUC: 0.9122\n",
      "\n",
      "   FEWSHOT_BASE:\n",
      "   - Model: adaface_ir_101 (mean)\n",
      "   - Rank-1: 63.41%\n",
      "   - ROC-AUC: 0.9143\n",
      "\n",
      "   ONESHOT_AUGMENTED:\n",
      "   - Model: adaface_ir_101 (mean)\n",
      "   - Rank-1: 61.28%\n",
      "   - ROC-AUC: 0.9408\n",
      "\n",
      "   ONESHOT_BASE:\n",
      "   - Model: adaface_ir_101 (max)\n",
      "   - Rank-1: 61.89%\n",
      "   - ROC-AUC: 0.9336\n",
      "\n",
      "3. MODEL RANKINGS (by best Rank-1 accuracy)\n",
      "   1. adaface_ir_101: 64.63%\n",
      "   2. arcface_ir_101: 59.45%\n",
      "   3. adaface_ir_50: 59.15%\n",
      "   4. arcface_ir_50: 53.35%\n",
      "\n",
      "4. BEST AGGREGATION METHOD PER GALLERY\n",
      "   fewshot_augmented: MEAN\n",
      "   fewshot_base: MEAN\n",
      "   oneshot_augmented: MEAN\n",
      "   oneshot_base: MAX\n",
      "\n",
      "5. KEY RECOMMENDATIONS\n",
      "   - Use adaface_ir_101 with fewshot_augmented gallery for best accuracy\n",
      "   - MEAN aggregation works best for this configuration\n",
      "   - Operating threshold: 0.200 for optimal performance\n",
      "   - All models achieve 100% impostor rejection at threshold â‰¥ 0.35\n",
      "\n",
      "6. LIMITATIONS\n",
      "   - Performance degrades significantly on high pitch and high yaw conditions\n",
      "   - Low quality images reduce accuracy by ~15-30%\n",
      "   - Baseline/frontal images show best performance (>90% Rank-1)\n",
      "\n",
      "================================================================================\n",
      "\n",
      "\n",
      "################################################################################\n",
      "# GENERATING COMPARISON VISUALIZATIONS\n",
      "################################################################################\n",
      "\n",
      "1. Creating model comparison charts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kevin\\AppData\\Local\\Temp\\ipykernel_14580\\1661849539.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  best_per_gallery = comparison_summary.groupby('Gallery').apply(\n",
      "C:\\Users\\kevin\\AppData\\Local\\Temp\\ipykernel_14580\\1595234252.py:80: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n",
      "  axes[idx].boxplot([genuine, impostor], labels=['Genuine', 'Impostor'])\n",
      "C:\\Users\\kevin\\AppData\\Local\\Temp\\ipykernel_14580\\1595234252.py:80: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n",
      "  axes[idx].boxplot([genuine, impostor], labels=['Genuine', 'Impostor'])\n",
      "C:\\Users\\kevin\\AppData\\Local\\Temp\\ipykernel_14580\\1595234252.py:80: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n",
      "  axes[idx].boxplot([genuine, impostor], labels=['Genuine', 'Impostor'])\n",
      "C:\\Users\\kevin\\AppData\\Local\\Temp\\ipykernel_14580\\1595234252.py:80: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n",
      "  axes[idx].boxplot([genuine, impostor], labels=['Genuine', 'Impostor'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison charts saved to: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\comparisons\\charts\n",
      "\n",
      "2. Creating segmented performance heatmaps...\n",
      "Segmented heatmap saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\comparisons\\charts\\segmented_oneshot_heatmap.png\n",
      "Segmented heatmap saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\comparisons\\charts\\segmented_fewshot_heatmap.png\n",
      "\n",
      "3. Creating gallery strategy visualizations...\n",
      "Gallery strategy plot saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\comparisons\\charts\\gallery_strategy_comparison.png\n",
      "\n",
      "################################################################################\n",
      "# EXPORTING COMPREHENSIVE REPORTS\n",
      "################################################################################\n",
      "Excel report saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\comparisons\\reports\\comprehensive_report.xlsx\n",
      "JSON report saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\comparisons\\reports\\comprehensive_report.json\n",
      "Text summary saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\comparisons\\reports\\executive_summary.txt\n",
      "LaTeX tables saved: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\comparisons\\reports\\latex_tables.tex\n",
      "\n",
      "================================================================================\n",
      "EVALUATION PIPELINE COMPLETE\n",
      "================================================================================\n",
      "\n",
      "All results saved to: d:\\KEVIN\\0SLC\\RIG\\output\\v0\n",
      "  - Individual results: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\evaluation_results\n",
      "  - Individual plots: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\plots\n",
      "  - Comparisons: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\comparisons\n",
      "  - Reports: d:\\KEVIN\\0SLC\\RIG\\output\\v0\\comparisons\\reports\n",
      "\n",
      "================================================================================\n",
      "EXECUTIVE SUMMARY - Face Recognition Evaluation\n",
      "Generated: 2025-12-05 16:31:47\n",
      "================================================================================\n",
      "\n",
      "KEY FINDINGS:\n",
      "\n",
      "1. OVERALL BEST PERFORMANCE\n",
      "   Model: adaface_ir_101\n",
      "   Configuration: fewshot_augmented + mean\n",
      "   Rank-1 Accuracy: 64.63%\n",
      "   ROC-AUC: 0.9122\n",
      "   d-prime: 1.542\n",
      "\n",
      "2. BEST CONFIGURATION PER GALLERY TYPE\n",
      "\n",
      "   FEWSHOT_AUGMENTED:\n",
      "   - Model: adaface_ir_101 (mean)\n",
      "   - Rank-1: 64.63%\n",
      "   - ROC-AUC: 0.9122\n",
      "\n",
      "   FEWSHOT_BASE:\n",
      "   - Model: adaface_ir_101 (mean)\n",
      "   - Rank-1: 63.41%\n",
      "   - ROC-AUC: 0.9143\n",
      "\n",
      "   ONESHOT_AUGMENTED:\n",
      "   - Model: adaface_ir_101 (mean)\n",
      "   - Rank-1: 61.28%\n",
      "   - ROC-AUC: 0.9408\n",
      "\n",
      "   ONESHOT_BASE:\n",
      "   - Model: adaface_ir_101 (max)\n",
      "   - Rank-1: 61.89%\n",
      "   - ROC-AUC: 0.9336\n",
      "\n",
      "3. MODEL RANKINGS (by best Rank-1 accuracy)\n",
      "   1. adaface_ir_101: 64.63%\n",
      "   2. arcface_ir_101: 59.45%\n",
      "   3. adaface_ir_50: 59.15%\n",
      "   4. arcface_ir_50: 53.35%\n",
      "\n",
      "4. BEST AGGREGATION METHOD PER GALLERY\n",
      "   fewshot_augmented: MEAN\n",
      "   fewshot_base: MEAN\n",
      "   oneshot_augmented: MEAN\n",
      "   oneshot_base: MAX\n",
      "\n",
      "5. KEY RECOMMENDATIONS\n",
      "   - Use adaface_ir_101 with fewshot_augmented gallery for best accuracy\n",
      "   - MEAN aggregation works best for this configuration\n",
      "   - Operating threshold: 0.200 for optimal performance\n",
      "   - All models achieve 100% impostor rejection at threshold â‰¥ 0.35\n",
      "\n",
      "6. LIMITATIONS\n",
      "   - Performance degrades significantly on high pitch and high yaw conditions\n",
      "   - Low quality images reduce accuracy by ~15-30%\n",
      "   - Baseline/frontal images show best performance (>90% Rank-1)\n",
      "\n",
      "================================================================================\n",
      "\n",
      "             Model            Gallery Aggregation    Rank-1    Rank-5  \\\n",
      "0    adaface_ir_50       oneshot_base         max  0.518293  0.746951   \n",
      "1    adaface_ir_50       oneshot_base        mean  0.518293  0.746951   \n",
      "2    adaface_ir_50       oneshot_base        topk  0.518293  0.746951   \n",
      "3    adaface_ir_50  oneshot_augmented         max  0.564024  0.762195   \n",
      "4    adaface_ir_50  oneshot_augmented        mean  0.545732  0.753049   \n",
      "5    adaface_ir_50  oneshot_augmented        topk  0.548780  0.753049   \n",
      "6    adaface_ir_50       fewshot_base         max  0.527439  0.753049   \n",
      "7    adaface_ir_50       fewshot_base        mean  0.588415  0.807927   \n",
      "8    adaface_ir_50       fewshot_base        topk  0.551829  0.777439   \n",
      "9    adaface_ir_50  fewshot_augmented         max  0.533537  0.753049   \n",
      "10   adaface_ir_50  fewshot_augmented        mean  0.591463  0.798780   \n",
      "11   adaface_ir_50  fewshot_augmented        topk  0.533537  0.750000   \n",
      "12  adaface_ir_101       oneshot_base         max  0.618902  0.807927   \n",
      "13  adaface_ir_101       oneshot_base        mean  0.618902  0.807927   \n",
      "14  adaface_ir_101       oneshot_base        topk  0.618902  0.807927   \n",
      "15  adaface_ir_101  oneshot_augmented         max  0.606707  0.792683   \n",
      "16  adaface_ir_101  oneshot_augmented        mean  0.612805  0.801829   \n",
      "17  adaface_ir_101  oneshot_augmented        topk  0.609756  0.795732   \n",
      "18  adaface_ir_101       fewshot_base         max  0.564024  0.807927   \n",
      "19  adaface_ir_101       fewshot_base        mean  0.634146  0.817073   \n",
      "20  adaface_ir_101       fewshot_base        topk  0.600610  0.807927   \n",
      "21  adaface_ir_101  fewshot_augmented         max  0.560976  0.789634   \n",
      "22  adaface_ir_101  fewshot_augmented        mean  0.646341  0.817073   \n",
      "23  adaface_ir_101  fewshot_augmented        topk  0.567073  0.798780   \n",
      "24   arcface_ir_50       oneshot_base         max  0.496951  0.731707   \n",
      "25   arcface_ir_50       oneshot_base        mean  0.496951  0.731707   \n",
      "26   arcface_ir_50       oneshot_base        topk  0.496951  0.731707   \n",
      "27   arcface_ir_50  oneshot_augmented         max  0.481707  0.704268   \n",
      "28   arcface_ir_50  oneshot_augmented        mean  0.487805  0.731707   \n",
      "29   arcface_ir_50  oneshot_augmented        topk  0.484756  0.719512   \n",
      "30   arcface_ir_50       fewshot_base         max  0.493902  0.728659   \n",
      "31   arcface_ir_50       fewshot_base        mean  0.533537  0.750000   \n",
      "32   arcface_ir_50       fewshot_base        topk  0.524390  0.743902   \n",
      "33   arcface_ir_50  fewshot_augmented         max  0.487805  0.698171   \n",
      "34   arcface_ir_50  fewshot_augmented        mean  0.533537  0.753049   \n",
      "35   arcface_ir_50  fewshot_augmented        topk  0.500000  0.719512   \n",
      "36  arcface_ir_101       oneshot_base         max  0.551829  0.737805   \n",
      "37  arcface_ir_101       oneshot_base        mean  0.551829  0.737805   \n",
      "38  arcface_ir_101       oneshot_base        topk  0.551829  0.737805   \n",
      "39  arcface_ir_101  oneshot_augmented         max  0.557927  0.740854   \n",
      "40  arcface_ir_101  oneshot_augmented        mean  0.557927  0.740854   \n",
      "41  arcface_ir_101  oneshot_augmented        topk  0.557927  0.743902   \n",
      "42  arcface_ir_101       fewshot_base         max  0.536585  0.737805   \n",
      "43  arcface_ir_101       fewshot_base        mean  0.594512  0.756098   \n",
      "44  arcface_ir_101       fewshot_base        topk  0.570122  0.743902   \n",
      "45  arcface_ir_101  fewshot_augmented         max  0.536585  0.728659   \n",
      "46  arcface_ir_101  fewshot_augmented        mean  0.585366  0.768293   \n",
      "47  arcface_ir_101  fewshot_augmented        topk  0.542683  0.740854   \n",
      "\n",
      "     Rank-10       MRR   ROC-AUC   d-prime  Best_Threshold  F1-Score  \\\n",
      "0   0.862805  0.630519  0.914966  1.360215             0.2  0.639004   \n",
      "1   0.862805  0.630519  0.914966  1.360215             0.2  0.639004   \n",
      "2   0.862805  0.630519  0.914966  1.360215             0.2  0.639004   \n",
      "3   0.853659  0.656832  0.885390  1.380328             0.2  0.666667   \n",
      "4   0.856707  0.648828  0.904278  1.380372             0.2  0.655738   \n",
      "5   0.859756  0.648779  0.903116  1.375690             0.2  0.661224   \n",
      "6   0.871951  0.635204  0.913966  1.400083             0.2  0.677419   \n",
      "7   0.887195  0.680541  0.922510  1.440159             0.2  0.672065   \n",
      "8   0.884146  0.654854  0.924118  1.426098             0.2  0.672065   \n",
      "9   0.875000  0.636037  0.885042  1.407712             0.2  0.688000   \n",
      "10  0.893293  0.684949  0.918449  1.453777             0.2  0.677419   \n",
      "11  0.878049  0.638448  0.901550  1.416427             0.2  0.685371   \n",
      "12  0.878049  0.700113  0.933557  1.473118             0.2  0.723735   \n",
      "13  0.878049  0.700113  0.933557  1.473118             0.2  0.723735   \n",
      "14  0.878049  0.700113  0.933557  1.473118             0.2  0.723735   \n",
      "15  0.884146  0.698678  0.933738  1.491488             0.2  0.731141   \n",
      "16  0.878049  0.699164  0.940847  1.488616             0.2  0.726214   \n",
      "17  0.875000  0.696871  0.939063  1.489494             0.2  0.731141   \n",
      "18  0.881098  0.677503  0.907390  1.492950             0.2  0.698413   \n",
      "19  0.881098  0.722048  0.914343  1.528113             0.2  0.713725   \n",
      "20  0.893293  0.699813  0.913551  1.506527             0.2  0.708661   \n",
      "21  0.881098  0.667316  0.906288  1.494465             0.2  0.706114   \n",
      "22  0.881098  0.728751  0.912248  1.541538             0.2  0.713725   \n",
      "23  0.875000  0.674991  0.895313  1.501863             0.2  0.698413   \n",
      "24  0.835366  0.604343  0.873285  1.245527             0.2  0.607219   \n",
      "25  0.835366  0.604343  0.873285  1.245527             0.2  0.607219   \n",
      "26  0.835366  0.604343  0.873285  1.245527             0.2  0.607219   \n",
      "27  0.826220  0.593580  0.894118  1.226415             0.2  0.624738   \n",
      "28  0.844512  0.598952  0.892485  1.247871             0.2  0.610169   \n",
      "29  0.832317  0.597345  0.885974  1.236862             0.2  0.618947   \n",
      "30  0.841463  0.602019  0.915700  1.221724             0.2  0.652977   \n",
      "31  0.859756  0.633826  0.889188  1.265916             0.2  0.630480   \n",
      "32  0.844512  0.627364  0.882976  1.246347             0.2  0.650206   \n",
      "33  0.835366  0.591997  0.888170  1.215817             0.2  0.652977   \n",
      "34  0.853659  0.635552  0.894753  1.278954             0.2  0.641822   \n",
      "35  0.847561  0.603134  0.892512  1.228483             0.2  0.655738   \n",
      "36  0.838415  0.647694  0.900477  1.367335             0.2  0.680080   \n",
      "37  0.838415  0.647694  0.900477  1.367335             0.2  0.680080   \n",
      "38  0.838415  0.647694  0.900477  1.367335             0.2  0.680080   \n",
      "39  0.844512  0.649034  0.889391  1.362564             0.2  0.685371   \n",
      "40  0.844512  0.651307  0.889278  1.370282             0.2  0.677419   \n",
      "41  0.841463  0.651971  0.891087  1.367010             0.2  0.682731   \n",
      "42  0.853659  0.638125  0.916343  1.357556             0.2  0.688000   \n",
      "43  0.850610  0.675692  0.927704  1.406816             0.2  0.708661   \n",
      "44  0.841463  0.657828  0.921834  1.385336             0.2  0.698413   \n",
      "45  0.844512  0.629647  0.813696  1.329643             0.2  0.695825   \n",
      "46  0.862805  0.671901  0.940908  1.412548             0.2  0.708661   \n",
      "47  0.862805  0.634928  0.900524  1.351843             0.2  0.700990   \n",
      "\n",
      "         TAR       FAR  \n",
      "0   0.469512  0.149390  \n",
      "1   0.469512  0.149390  \n",
      "2   0.469512  0.149390  \n",
      "3   0.500000  0.192073  \n",
      "4   0.487805  0.137195  \n",
      "5   0.493902  0.170732  \n",
      "6   0.512195  0.271341  \n",
      "7   0.506098  0.070122  \n",
      "8   0.506098  0.155488  \n",
      "9   0.524390  0.371951  \n",
      "10  0.512195  0.070122  \n",
      "11  0.521341  0.323171  \n",
      "12  0.567073  0.097561  \n",
      "13  0.567073  0.097561  \n",
      "14  0.567073  0.097561  \n",
      "15  0.576220  0.149390  \n",
      "16  0.570122  0.100610  \n",
      "17  0.576220  0.125000  \n",
      "18  0.536585  0.243902  \n",
      "19  0.554878  0.085366  \n",
      "20  0.548780  0.155488  \n",
      "21  0.545732  0.329268  \n",
      "22  0.554878  0.085366  \n",
      "23  0.536585  0.274390  \n",
      "24  0.435976  0.198171  \n",
      "25  0.435976  0.198171  \n",
      "26  0.435976  0.198171  \n",
      "27  0.454268  0.246951  \n",
      "28  0.439024  0.185976  \n",
      "29  0.448171  0.222561  \n",
      "30  0.484756  0.289634  \n",
      "31  0.460366  0.134146  \n",
      "32  0.481707  0.189024  \n",
      "33  0.484756  0.454268  \n",
      "34  0.472561  0.131098  \n",
      "35  0.487805  0.375000  \n",
      "36  0.515244  0.161585  \n",
      "37  0.515244  0.161585  \n",
      "38  0.515244  0.161585  \n",
      "39  0.521341  0.213415  \n",
      "40  0.512195  0.161585  \n",
      "41  0.518293  0.185976  \n",
      "42  0.524390  0.277439  \n",
      "43  0.548780  0.106707  \n",
      "44  0.536585  0.164634  \n",
      "45  0.533537  0.429878  \n",
      "46  0.548780  0.106707  \n",
      "47  0.539634  0.381098  \n",
      "            Model  Oneshot_Base  Oneshot_Aug  Fewshot_Base  Fewshot_Aug  \\\n",
      "0   adaface_ir_50      0.518293     0.564024      0.588415     0.591463   \n",
      "1  adaface_ir_101      0.618902     0.612805      0.634146     0.646341   \n",
      "2   arcface_ir_50      0.496951     0.487805      0.533537     0.533537   \n",
      "3  arcface_ir_101      0.551829     0.557927      0.594512     0.585366   \n",
      "\n",
      "   Aug_Improvement_Oneshot  Aug_Improvement_Fewshot  Fewshot_Improvement_Base  \\\n",
      "0                 0.045732                 0.003049                  0.070122   \n",
      "1                -0.006098                 0.012195                  0.015244   \n",
      "2                -0.009146                 0.000000                  0.036585   \n",
      "3                 0.006098                -0.009146                  0.042683   \n",
      "\n",
      "   Fewshot_Improvement_Aug        Best_Config  Best_Rank1  \n",
      "0                 0.027439  fewshot_augmented    0.591463  \n",
      "1                 0.033537  fewshot_augmented    0.646341  \n",
      "2                 0.045732       fewshot_base    0.533537  \n",
      "3                 0.027439       fewshot_base    0.594512  \n"
     ]
    }
   ],
   "source": [
    "all_results, all_summaries = run_complete_evaluation_pipeline(\n",
    "    all_embeddings,\n",
    "    output_root\n",
    ")\n",
    "\n",
    "print(all_summaries['executive_summary'])\n",
    "print(all_summaries['comparison_summary'])\n",
    "print(all_summaries['gallery_strategy'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adaface",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
